{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Добро пожаловать на задание уровня Lite.\n",
        "\n",
        "В данном задании требуется на базе текстов добиться ошибки меньше 0.2, причем потребуется это сделать за 5 эпох (Во избежание слишком долгого ожидания обучения).\n",
        "\n",
        "Подсказка: В данной задаче поможет подбор гиперпараметров и можно взять за основу ноутбук практики.\n",
        "\n",
        "Успехов!"
      ],
      "metadata": {
        "id": "LSuU8TGeDbiB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# модуль для загрузки файлов в colab\n",
        "from google.colab import files \n",
        "\n",
        "# Подключим tensorflow\n",
        "import tensorflow as tf \n",
        "\n",
        "# Подключим токенайзер\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "# Используем метод для формирования последовательностей одинаковой длины\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences \n",
        "\n",
        "# Загружаем абстрактный класс базовой модели сети от кераса\n",
        "from tensorflow.keras.models import Model \n",
        "\n",
        "# Подключим необходимые слои\n",
        "from tensorflow.keras.layers import Dense, Embedding, GRU\n",
        "\n",
        "# Подключим оптимайзер\n",
        "from tensorflow.keras.optimizers import Adam \n",
        "\n",
        "# Подключим функцию потерь\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
        "\n",
        "# Подключим numpy - библиотеку для работы с массивами данных\n",
        "import numpy as np \n",
        "\n",
        "# Подключим библиотеку для визуализации данных\n",
        "import matplotlib.pyplot as plt \n",
        "\n",
        "# Подключим модуль для определения форматирования и местоположения делений на осях графиков\n",
        "import matplotlib.ticker as ticker \n",
        "\n",
        "# Подключим модуль для разбивки данных на обучающую и тестовую выборки\n",
        "from sklearn.model_selection import train_test_split \n",
        "\n",
        "# Подключим модуль для работы с регулярными выражениями\n",
        "import re \n",
        "\n",
        "# Подключим модуль для работы с временем\n",
        "import time\n",
        "\n",
        "# Подключим модуль для работы с операционной системой\n",
        "import os "
      ],
      "metadata": {
        "id": "m0vddHg6O-7v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Скачаем датасет из пар фраз на русском и английском языках \n",
        "!wget  http://www.manythings.org/anki/rus-eng.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gtPnDxjeO-_C",
        "outputId": "b574c974-ef38-4dca-c16b-b6fa1516bf0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-12-28 14:44:14--  http://www.manythings.org/anki/rus-eng.zip\n",
            "Resolving www.manythings.org (www.manythings.org)... 173.254.30.110\n",
            "Connecting to www.manythings.org (www.manythings.org)|173.254.30.110|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 15011848 (14M) [application/zip]\n",
            "Saving to: ‘rus-eng.zip’\n",
            "\n",
            "rus-eng.zip         100%[===================>]  14.32M  9.20MB/s    in 1.6s    \n",
            "\n",
            "2022-12-28 14:44:16 (9.20 MB/s) - ‘rus-eng.zip’ saved [15011848/15011848]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Распакуем скачанные тексты и убедимся в появлении файла со словарем:\n",
        "\n",
        "!unzip -o rus-eng.zip "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sBTea8y1O_Cn",
        "outputId": "720b652b-c4ef-488e-bda1-4b58e598b331"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  rus-eng.zip\n",
            "  inflating: rus.txt                 \n",
            "  inflating: _about.txt              \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Проверим распакованные файлы\n",
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WfkNY0ptO_FW",
        "outputId": "5579a6aa-3376-4393-dcb0-811e145a1864"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "_about.txt  rus-eng.zip  rus.txt  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Определим переменную с именем файла с датасетом\n",
        "path_to_file=\"rus.txt\""
      ],
      "metadata": {
        "id": "N3-vRiL_O_Ii"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Определим функцию для подготовки предложений из словаря для обучения нейронной сети.\n",
        "# Добавим пробелы между словами и знаками препинаний, служебные символы заменим на пробелы, \n",
        "#уберем пробелы в начале и конце фразы., добавим тег < start > в начало фразы, < end > в конец:"
      ],
      "metadata": {
        "id": "IxEa-jgUO_Lr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_sentence(phrases): # Функция принимает содержимое словаря\n",
        "\n",
        "  # Разделяем пробелами слова и знаки препинания(\"А как насчет тебя? \" -> \"А как насчет тебя ? \") \n",
        "  phrases = re.sub(r\"([?.!,;:])\", r\" \\1 \", phrases) # r\" \\1 \" берёт значения 1й группы в скобках; обрамляем указанные символы пробелами\n",
        "\n",
        "  # Заменяем всё на пробелы, за исключением (a-zA-Zа-яёА-ЯЁ?.!,;:)\n",
        "  phrases = re.sub(r\"[^a-zA-Zа-яёА-ЯЁ?.!,;:]+\", \" \", phrases) \n",
        "  \n",
        "  # Получаем строку без случайных лишних пробелов в конце фраз(rstrip удаляет с конца строки)\n",
        "  phrases = phrases.rstrip().strip()      \n",
        "\n",
        "  # Для нашей модели обозначим тегами начало и конец предложения  \n",
        "  phrases = '<start> ' + phrases + ' <end>' \n",
        "\n",
        "  # Функция возвращает предобработанные фразы\n",
        "  return phrases "
      ],
      "metadata": {
        "id": "voZBs6CaOjHD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Покажем пример обработки фразц\n",
        "\n",
        "print(\"Фразы после обработки функцией с т.з. пунктуации примут вид:\") \n",
        "print(preprocess_sentence(\"What about you?\"))                         # Выведем пример до обработки \n",
        "print(preprocess_sentence(\"А как насчет тебя?\"))                      # И после"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D18S1xrKOpIn",
        "outputId": "c208c591-e87c-45e8-bdd3-e148c6475304"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Фразы после обработки функцией с т.з. пунктуации примут вид:\n",
            "<start> What about you ? <end>\n",
            "<start> А как насчет тебя ? <end>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Функция создания датасета\n",
        "\n",
        "def create_dataset(path,          # Путь к файлу\n",
        "                   num_examples): # Необходимый размер датасета \n",
        "\n",
        "  # Открываем файл и разбиваем фразы на отдельные строчки\n",
        "  lines = open(path, encoding='UTF-8').read().strip().split('\\n')\n",
        "\n",
        "  # В каждой строке словаря разделяем английскую фразу от русской, и пропускаем через функцию предобработки данных\n",
        "  word_pairs = [[preprocess_sentence(phrases) for phrases in l.split('\\t')[0:2]]  for l in lines[:num_examples]]\n",
        "\n",
        "  # Вернем пары фраз в виде [по-английски, по-русски]\n",
        "  return zip(*word_pairs)\n"
      ],
      "metadata": {
        "id": "gxCd0Vr4OpMD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Взглянем на пример пары фраз на выходе функции:\")\n",
        "\n",
        "english, russian = create_dataset(path_to_file,40000) # Вызовем функцию для демонстрации\n",
        "print(english[-1])                                    # Выведем последний элемент из списка английских фраз\n",
        "print(russian[-1])                                    # Выведем последний элемент из списка русских фраз"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89JxvrReOpOx",
        "outputId": "832a6eb9-03c5-4cf4-b9d3-d45a8423b227"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Взглянем на пример пары фраз на выходе функции:\n",
            "<start> Can I do it again ? <end>\n",
            "<start> Могу я сделать это снова ? <end>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Создадим мини-функцию, возвращающую максимальную длину тензора\n",
        "def max_length(tensor): # Функция принимает на вход тензор(фразы в виде последовательности индексов)\n",
        "\n",
        "  # Вернем значение максимальной длины его элемента \n",
        "  return max(len(t) for t in tensor) "
      ],
      "metadata": {
        "id": "mSSFL95sOpVF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Функция преобразовывает тексты в последовательности индексов. Используем стандартный токенайзер из модуля Keras. \n",
        "#На вход принимает текст, обучает на нем токенайзер. Переводит текст в токены. Отдает полученые токены и токенайзер"
      ],
      "metadata": {
        "id": "Pnkzd3tlP_7x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(language): # Функция принимает текст одного из языков\n",
        "\n",
        "  language_tokenizer = Tokenizer(filters='')               # Вызываем класс Токенизатор, просим его не удалять символы, которые он удаляет по умолчанию\n",
        "  language_tokenizer.fit_on_texts(language)                # \"скармливаем\" ему тексты для обработки и сборки словаря частотности\n",
        "  tensor = language_tokenizer.texts_to_sequences(language) # Разбиваем текст фраз на последовательности индексов\n",
        "  tensor = pad_sequences(tensor, padding='post')           # Делаем последовательности фиксированной длины, заполняя нулями более короткие фразы\n",
        "\n",
        "  # Возвращаем последовательность индексов(назовем ее тензор) и токенизатор\n",
        "  return tensor, language_tokenizer "
      ],
      "metadata": {
        "id": "eEBzAPYRPPr3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Функция формирующая готовый датасет. Получает на вход путь к файлу с текстами и необходимый размер готового датасета"
      ],
      "metadata": {
        "id": "uGYUvYtxO_OX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dataset(path,               # Путь к файлу с текстами\n",
        "                 num_examples=None): # Необходимый объем датасета\n",
        "\n",
        "    # Из исходного текста делаем датасет пар фраз, причём входным языком для сети сделаем русский\n",
        "    targ_language, inp_language = create_dataset(path, num_examples)\n",
        "\n",
        "    # Разбиваем текст на последовательность индексов(назовем ее тензор)\n",
        "    input_tensor, inp_language_tokenizer = tokenize(inp_language)    # Формируем тензоры и токенизатор для русского языка\n",
        "    target_tensor, targ_language_tokenizer = tokenize(targ_language) # Формируем тензоры и токенизатор для английского языка\n",
        "\n",
        "    # Функция вернёт: тензор для русского языка, для английского языка; токенизаторы для русского и английского языков\n",
        "    return input_tensor, target_tensor, inp_language_tokenizer, targ_language_tokenizer"
      ],
      "metadata": {
        "id": "QyI4ufU5PcJN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Формируем датасет заданного объема - 40000 (в зависимости от приоритета скорости либо качества обучения), \n",
        "#используем ранее написанные функции:"
      ],
      "metadata": {
        "id": "JCuPjJmzQY0v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_examples = 40000 # Выберем 40 тысяч строк(всего в базе около 360тысяч строк, в каждой пара фраз)\n",
        "\n",
        "input_tensor, target_tensor, inp_language_tokenizer, targ_language_tokenizer = load_dataset(path_to_file, num_examples)\n",
        "\n",
        "# Вычислим максимальные длины тензоров для английского и русского языков, используя ранее заданную функцию\n",
        "max_length_targ, max_length_inp = max_length(target_tensor), max_length(input_tensor)\n",
        "\n",
        "# Создаем тренировочную и тестовую выборки по формуле 80/20\n",
        "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)"
      ],
      "metadata": {
        "id": "WpV_nX2dP3O7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Создадим вспомогательную функцию для вывода слова фразы и его индекса. На вход подаются токенайзер и фраза:"
      ],
      "metadata": {
        "id": "h1QfL67tQY6k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Визуализируем собранные данные\n",
        "\n",
        "def convert(language_tokenizer,  # Токенайзер\n",
        "            tensor):             # Список индексов слов\n",
        "            \n",
        "  #  Цикл по токенам во фразе\n",
        "  for t in tensor:  \n",
        "    if t!=0:                                                        # Если токен не 0. Т.е. не мусор в конце фразы\n",
        "      print (\"%d ----> %s\" % (t, language_tokenizer.index_word[t])) # Выводи токен и соответствующее слово"
      ],
      "metadata": {
        "id": "6xF6ILPrQY3W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Посмотрим на примеры В первом блоке выведем русскую фразу и ее токен Во втором агнлийскую.\n",
        "#Далее выводим статистику по датасету"
      ],
      "metadata": {
        "id": "NDcl1Q69IHNy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print (\"Фраза на русском языке; соответствие индекса и слова\")   \n",
        "convert(inp_language_tokenizer, input_tensor_train[0])           # Выведем нулевую пару из русского датасета\n",
        "print ()    \n",
        "\n",
        "print (\"Фраза на английском языке; соответствие индекса и слова\")\n",
        "convert(targ_language_tokenizer, target_tensor_train[0])         # Выведем нулевую пару из агнлийского датасета\n",
        "print ()   \n",
        "                                                      \n",
        "print(\"Рус.яз. тренировочная: \" , len(input_tensor_train), \"фраз; \", \"Анг.яз. тренировочная: \", len(target_tensor_train), \"фраз\")# Выведем статистику по обучающей выборке\n",
        "print(\"Рус.яз. тестовая: \", len(input_tensor_val), \"фраз; \", \"Анг.яз. тестовая: \", len(target_tensor_val), \"фраз\")               # Выведем статистику по тестовой выборке"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j4pEdQhsScZw",
        "outputId": "4c3f72b6-a201-4089-8c6f-f2937c773753"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Фраза на русском языке; соответствие индекса и слова\n",
            "1 ----> <start>\n",
            "45 ----> люблю\n",
            "3869 ----> весну\n",
            "3 ----> .\n",
            "2 ----> <end>\n",
            "\n",
            "Фраза на английском языке; соответствие индекса и слова\n",
            "1 ----> <start>\n",
            "4 ----> i\n",
            "39 ----> like\n",
            "790 ----> spring\n",
            "3 ----> .\n",
            "2 ----> <end>\n",
            "\n",
            "Рус.яз. тренировочная:  32000 фраз;  Анг.яз. тренировочная:  32000 фраз\n",
            "Рус.яз. тестовая:  8000 фраз;  Анг.яз. тестовая:  8000 фраз\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Создаем tf.data датасет (Раздел tf.data.Dataset API предлагает построить готовый конвейер для обучения моделей)"
      ],
      "metadata": {
        "id": "YxiGPfWfIHTq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Здесь заменим гиперпараметры:\n"
      ],
      "metadata": {
        "id": "-6K4X4LXIbPm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Определим постоянные \n",
        "\n",
        "BUFFER_SIZE = len(input_tensor_train)                     # Укажем что случайно сэмплировать будем по всей длине обучающейся выборки\n",
        "BATCH_SIZE = 128                                          # Указываем размер батча\n",
        "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE     # Укажем количество шагов в одной эпохе\n",
        "embedding_dim = 512                                       # Размерность эмбеддинга, векторного пространства\n",
        "units = 2048                                              # Задаем размер слоя(количество нейронов в слое) "
      ],
      "metadata": {
        "id": "OBqJGnUDTFIo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Задаем размер русского словаря\n",
        "vocab_inp_size = len(inp_language_tokenizer.word_index)+1 \n",
        "\n",
        "# Задаем размер английского словаря\n",
        "vocab_tar_size = len(targ_language_tokenizer.word_index)+1 \n",
        "\n",
        "# Создаём датасет из массивов Numpy(рус и анг тренировочные фразы) со случайной подачей тренировочных сэмплов в процессе обучения\n",
        "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
        "\n",
        "# Передаем в датасет размер батча и указываем, что если в тренировке последний батч окажется неполным, то опустим его\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
      ],
      "metadata": {
        "id": "9_H9xYqWTxpB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Посмотрим на форму примеров полученных батчей\n",
        "\n",
        "example_input_batch, example_target_batch = next(iter(dataset))\n",
        "example_input_batch.shape, example_target_batch.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pmLENb5yTxzy",
        "outputId": "6a5e0c19-3f6c-4c04-e81d-e729ce0028c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([128, 12]), TensorShape([128, 9]))"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "N3smos9JV0Fh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Вспомним нашу схему - сеть состоит их кодера, декодера и блока attention.\n",
        "#Давайте начнем оформлять кодер в виде класса. В этом примере кодер состоит из блоков Embedding и GRU. \n",
        "#Обратим внимание на return_sequences=True, return_state=True - мы требуем состояния кодера на каждом шаге работы.\n",
        "#На вход принимает фразу для перевода и начальное состояние. Отдает выход GRU и вектор скрытых состояний"
      ],
      "metadata": {
        "id": "g3BrDYVeQY9U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(Model):\n",
        "\n",
        "  # Конструктор класса \n",
        "  def __init__(self, \n",
        "               vocab_size,    # Размер словаря\n",
        "               embedding_dim, # Размер пространсва эмбеддинга\n",
        "               enc_units,     # Число нейронов в GRU\n",
        "               batch_sz):     # Размер батча\n",
        "\n",
        "    super(Encoder, self).__init__()                                   # Даем возможность использовать и исполнять методы класса-родителя в классе потомке \n",
        "    self.batch_sz = batch_sz                                          # Атрибут возвращает размер батча\n",
        "    self.enc_units = enc_units                                        # Атрибут возвращает размер слоя в кодировщике\n",
        "    self.embedding = Embedding(vocab_size, embedding_dim)             # Атрибут эмбеддинга - слой Кераса с размером словаря на входе и с dim=512\n",
        "\n",
        "    # Реккурентной сетью выберем GRU, указываем размер слоя, вывод из слоя в виде последовательностей, \n",
        "    # и метод инициализации весов 'glorot_uniform'(или метод Ксавьера) для упрощения прохождения сигнала при распростр-ии ошибки\n",
        "    self.gru = GRU(self.enc_units, return_sequences=True, return_state=True, recurrent_initializer='glorot_uniform')\n",
        "\n",
        "  # Метод принимает входную фразу и начальное состояние\n",
        "  def call(self, \n",
        "           x,       # Входная фраза\n",
        "           hidden): # Начальное энкодера\n",
        "    x = self.embedding(x) # входящие тензоры преобразовываются в эмбеддинг\n",
        "    output, state = self.gru(x, initial_state = hidden) #затем пропускаются через GRU и получаем выход + новое состояние\n",
        "\n",
        "    # Выход сети GRU и состояние на выходе\n",
        "    return output, state \n",
        "\n",
        "  # Создаем метод инициализации состояний на скрытых слоях\n",
        "  def initialize_hidden_state(self):\n",
        "\n",
        "    # Вернем тензор из нулей размер батча на размер слоя, итсполбьзуем как начальное состояние энкодера\n",
        "    return tf.zeros((self.batch_sz, self.enc_units)) "
      ],
      "metadata": {
        "id": "MlaykMNCV2BD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Создаем экземпляр класса Encoder. Используем далее как готовый модуль при построении модели сети"
      ],
      "metadata": {
        "id": "Yw-WKBN8WOzs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Создадим модель кодировщика по уже заданным параметрам \n",
        "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)"
      ],
      "metadata": {
        "id": "4l44Q8NVWO7m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Подадим в качестве примера какой-то сэмпл(Тензор[64, 12]) на вход Encoder'у и визуализируем, что получим\n",
        "sample_hidden = encoder.initialize_hidden_state() #инициализируем начальное скрытое состояние\n",
        "\n",
        "# Даем Encoder'у сэмпл и начальное состояние, и получим выход из сети GRU и состояние на выходе (вызывается метод call класса Encoder)\n",
        "sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n",
        "print ('Размеры выхода из кодировщика: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
        "print ('Размеры скрытого состояния: (batch size, units) {}'.format(sample_hidden.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "asdboKCrWO_G",
        "outputId": "65c349b9-8f2c-4ac8-e9db-c8c210360f82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Размеры выхода из кодировщика: (batch size, sequence length, units) (128, 12, 2048)\n",
            "Размеры скрытого состояния: (batch size, units) (128, 2048)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Создадим класс модуля attenton, как предписывал Bahdanau. Разбор работы данного модуля мы прошли чуть ранее. \n",
        "#На входе состояния кодера hidden_state и values - выход предыдущего декодера с предыдущего шага. На выходе вектор контекста и веса attention:"
      ],
      "metadata": {
        "id": "dw67hnGeWPCP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BahdanauAttention(Model): # Название класса именем создателя механизма Дмитрия Богданова(Bahdanau)\n",
        "\n",
        "  # Создаем конструктор класса\n",
        "  def __init__(self, \n",
        "               units):                        # Число нейронов \n",
        "\n",
        "    super(BahdanauAttention, self).__init__() # Даем возможность использовать и исполнять методы класса-родителя в классе потомке\n",
        "    self.W1 = Dense(units)                    # Создаем Dense с заданным числом нейронов\n",
        "    self.W2 = Dense(units)                    # Создаем Dense с заданным числом нейронов\n",
        "    self.V =  Dense(1)                        # Создаем Dense с числом нейронов =1\n",
        "\n",
        "  # Метод принимает состояние и выход энкодера ----------------------------------\n",
        "  \n",
        "  def call(self, \n",
        "           hidden_state, # Состояние энкодера\n",
        "           values):      # Выход энкодера\n",
        "    # Форма состояния на скрытом слое (batch_size, hidden size)\n",
        "    # Форму состояния на каждом такте увеличим до (batch_size, 1, hidden size)\n",
        "    # Добавляем это для того, чтобы получить оценку\n",
        "    hidden_with_time_axis = tf.expand_dims(hidden_state, 1)\n",
        "\n",
        "    # Форма оценки score (размер батча, макс.длина слов на входе, 1), однёрка в конце, чтобы применить self.V\n",
        "    # До применения self.V оценка была бы (размер батча, макс.длина слов на входе, количество нейронов в слое)\n",
        "    score = self.V(tf.nn.tanh(self.W1(values) + self.W2(hidden_with_time_axis)))\n",
        "\n",
        "    # К полученной оценке применим Софтмакс, который покажет вероятность полезности от 0 до 1 для каждого слова в фразе для декодера\n",
        "    # Форма оценки score - (размер батча, макс.длина слов на входе, 1); Софтмакс применяем к оси \"макс.длина слов\"\n",
        "    attention_weights = tf.nn.softmax(score, axis=1)\n",
        "\n",
        "    # Построим вектор контекста \n",
        "    context_vector = attention_weights * values # Веса внимания перемножим со значениями(выхода из кодировщика)\n",
        "    # Сумму также применяем по оси \"макс.длина слов на входе\"\n",
        "    context_vector = tf.reduce_sum(context_vector, axis=1) # Размеры вектора контекста после суммирования будут (размер батча, размер слоя)\n",
        "\n",
        "    # Возвращает вектор контекста и веса внимания\n",
        "    return context_vector, attention_weights"
      ],
      "metadata": {
        "id": "DIAMB4D2WhFb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Создадим экземпляр класса BahdanauAttention.\n",
        "#Изменим количество нейронов в блоке внимания"
      ],
      "metadata": {
        "id": "p344NfjzJhF8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Проверим, как работает слой\n",
        "attention_layer = BahdanauAttention(10)\n",
        "\n",
        "# Подадим на вход слою внимания выход из Encodera и его состояние, и получим значение и веса внимания\n",
        "attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n",
        "\n",
        "print(\"Размеры значения внимания: (размер батча, размер слоя) {}\".format(attention_result.shape))\n",
        "print(\"Размеры весов внимания: (размер батча, длина последовательности, 1) {}\".format(attention_weights.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_ZG4R9qW5jX",
        "outputId": "2eda341a-44db-425b-ea8e-8c773ec55a48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Размеры значения внимания: (размер батча, размер слоя) (128, 2048)\n",
            "Размеры весов внимания: (размер батча, длина последовательности, 1) (128, 12, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Создаем класс декодера с attention. Декодер принимает обущающую фразу, прогоняет через embedding. \n",
        "#Далее склеивает с вектором контента и подает на GRU. На выходе dense слой с числом нейронов равному размеру словаря."
      ],
      "metadata": {
        "id": "uiu_G4S5Jsw2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(Model):\n",
        "\n",
        "  # Создадим конструктор класса\n",
        "  def __init__(self,   \n",
        "               vocab_size,    # Размер словаря\n",
        "               embedding_dim, # Размерность пространства эмбеддинга\n",
        "               dec_units,     # Число нейронов в GRU\n",
        "               batch_sz):     # Размер батча\n",
        "    super(Decoder, self).__init__()                       # Даем возможность использовать и исполнять методы класса-родителя в классе потомке \n",
        "    self.batch_sz = batch_sz                              # Атрибут возвращает размер батча\n",
        "    self.dec_units = dec_units                            # Атрибут возвращает размер слоя в декодере(кол-во нейронов)\n",
        "    self.embedding = Embedding(vocab_size, embedding_dim) # Атрибут эмбеддинга - слой Кераса с размером словаря на входе и (dim=256) на выходе\n",
        "\n",
        "    # Реккурентной сетью выберем GRU, указываем размер слоя, вывод из слоя в виде последовательностей, \n",
        "    # и метод инициализации весов 'glorot_uniform'(или метод Ксавьера) для упрощения прохождения сигнала при распростр-ии ошибки    \n",
        "    self.gru = GRU(self.dec_units, return_sequences=True, return_state=True, recurrent_initializer='glorot_uniform')\n",
        "\n",
        "    self.fc = Dense(vocab_size) # Атрибут вызовет полносвязный слой с размером словаря\n",
        "\n",
        "    self.attention = BahdanauAttention(self.dec_units) #атрибут подключит механизм внимания, описанный ранее\n",
        "\n",
        "\n",
        "  def call(self, \n",
        "           x,           # Начальный токен\n",
        "           hidden,      # Состояние  энкодера\n",
        "           enc_output): # Выход энкодера\n",
        "\n",
        "    # Enc_output размеры (batch_size, max_length, hidden_size - размер батча, макс.длина фраз, разм.скр.слоя)\n",
        "    context_vector, attention_weights = self.attention(hidden, enc_output)\n",
        "\n",
        "    # Входящий тензор слова пропускаем через эмбеддинг (получаем размеры batch_size, 1, embedding_dim)\n",
        "    x = self.embedding(x)\n",
        "\n",
        "    # Дальше конкатенируем с вектором контекста (получаем размеры batch_size, 1, embedding_dim + hidden_size)\n",
        "    x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
        "\n",
        "    # Сконкатенированный вектор передаем  в GRU и получаем выход с декодера и состояние\n",
        "    output, state = self.gru(x)\n",
        "\n",
        "    # Output размеры (batch_size * 1, hidden_size)\n",
        "    output = tf.reshape(output, (-1, output.shape[2]))\n",
        "\n",
        "    # Пропускаем через полносвязный слой\n",
        "    x = self.fc(output) #output размеры (batch_size, vocab)\n",
        "\n",
        "    # Вернем выходную фразу, вектор состояния, веса внимания\n",
        "    return x, state, attention_weights"
      ],
      "metadata": {
        "id": "yxlbFaJHXEvK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Проверим работу декодера, подав на вход случайный массив с нужной размерностью\n",
        "# Создали декодер с параметрами(размер анг.словаря, размерность эмбеддинга, кол-во нейронов, размер батча)\n",
        "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
        "\n",
        "# Подаём на вход случайный массив с нужной размерностью, состояние и выход с кодировщика\n",
        "sample_decoder_output, _, _ = decoder(tf.random.uniform((BATCH_SIZE, 1)), sample_hidden, sample_output)\n",
        "print ('Размер выхода с декодера: (размер батча, размер словаря) {}'.format(sample_decoder_output.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i-9KORjlXPGn",
        "outputId": "e3cef267-b891-454e-ee7d-69ff14028064"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Размер выхода с декодера: (размер батча, размер словаря) (128, 4293)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#В ячейке ниже в tf.random.uniform((... , 1)) вместо ... поставим BATCH_SIZE."
      ],
      "metadata": {
        "id": "TM9rCbBSJs3h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Выбираем оптимайзер Adam\n",
        "optimizer = Adam() "
      ],
      "metadata": {
        "id": "tVfC5Ln6JhQI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Наша функция потерь называется loss_function - сначала она уберет из расчетов нулевые элементы в истинной и предсказанной фразе.\n",
        "#Длина фразы может быть меньше максимально допустимой или фраза может быть сформирована не полностью. Просто не будем учитывать мусор в конце фразы.\n",
        "#Далее применим стандартную для Kerasa функцию потерь SparseCategoricalCrossentropy. \n",
        "#По сравнению CategoricalCrossentropy работает также, но позволяет нам не хранить слова в виде OneHotEncoding, что существенно экономить память.\n",
        "#На выходе получаем среднее значение потерь:"
      ],
      "metadata": {
        "id": "4k5maAkIQZAA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Используем SparseCategoricalCrossentropy, к-я может работать с некатегориальными лейблами\n",
        "loss_object = SparseCategoricalCrossentropy(from_logits=True, reduction='none') # Выбираем функцию потерь\n",
        "\n",
        "def loss_function(real, pred):                       # Запишем функцию потерь, на вход подаем фактический и предсказанный результат\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0)) # Найдем маску, которая уберет нулевые значения индексов в конце фразы\n",
        "  loss_ = loss_object(real, pred)                    # Фактические и предсказанные результаты передаем в SparseCategoricalCrossentropy и получаем ошибку\n",
        "  mask = tf.cast(mask, dtype=loss_.dtype)            # Согласуем тип маски с типом потерь\n",
        "  loss_ *= mask                                      # Накидываем \"маску\" которая оставит для работы ненулевые значения\n",
        "  \n",
        "  # Вернем reduce_mean - среднее любого выбранного тензора\n",
        "  return tf.reduce_mean(loss_)"
      ],
      "metadata": {
        "id": "0ffSFO2PXvUd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Сохраняем процесс обучения модели чекпоинтами тензорфлоу\n",
        "\n",
        "checkpoint_dir = './training_checkpoints'                                               # Даем ссылку на директорию\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")                                # Добавляем префикс \"ckpt\"\n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer, encoder=encoder, decoder=decoder) # Сохраняем состояния/показатели оптимизатора и моделей"
      ],
      "metadata": {
        "id": "T2wsW1IsX97T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Создадим функцию для обучения модели. На входе - исходная фраза, конечная фраза, начальное состояния кодера.\n",
        "# Подаем сразу батчем. На выходе потери на этом батче"
      ],
      "metadata": {
        "id": "_JY9BnPoKV_w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def train_step(inp,         # Входная фраза\n",
        "               targ,        # Точный перевод\n",
        "               enc_hidden): # Состояния энкодера\n",
        "\n",
        "  # Создаем переменную, в которую будем записывать ошибку\n",
        "  loss = 0                             \n",
        "\n",
        "  # Все операции по вычислению градиента записываются на ленту(tape) и мы получаем к ним доступ\n",
        "  with tf.GradientTape() as tape:\n",
        "\n",
        "    # Передаем тензор и начальное состояние в кодировщик и получим выход и состояние на выходе\n",
        "    enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
        "\n",
        "    # Передадим это состояние декодеру\n",
        "    dec_hidden = enc_hidden\n",
        "\n",
        "    # Передаем в качестве входа в декодер индекс токена \"<start>\"\n",
        "    dec_input = tf.expand_dims([targ_language_tokenizer.word_index['<start>']] * BATCH_SIZE, 1)\n",
        "\n",
        "    # Техника \"Teacher forcing\" - подаем предыдущее выходное слово на вход следущего в декодере. Targ.shape[64, 9]\n",
        "\n",
        "    for t in range(1, targ.shape[1]): #для каждого слова из английской фразы\n",
        "\n",
        "      # Передаем в обработку декодеру начальный токен, состояние на выходе из кодера, и выход из кодера\n",
        "      predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output) # Получаем от декодера предсказание и обновленное состояние\n",
        "\n",
        "      # Обновляем ошибку для текущих предсказаний\n",
        "      loss += loss_function(targ[:, t], predictions)\n",
        "\n",
        "      # Используем \"Teacher forcing\"\n",
        "      dec_input = tf.expand_dims(targ[:, t], 1)\n",
        "\n",
        "  # Получаем ошибку на батче . Targ.shape[64, 9]. Делим на 9\n",
        "  batch_loss = (loss / int(targ.shape[1])) \n",
        "\n",
        "  # Создаем список переменных, для которых TensorFlow будет вычислять градиенты\n",
        "  variables = encoder.trainable_variables + decoder.trainable_variables # создаем переменные, для которых TensorFlow будет вычислять градиенты\n",
        "\n",
        "  # Отслеживаем градиент\n",
        "  gradients = tape.gradient(loss, variables)\n",
        "\n",
        "  # Корректируем веса\n",
        "  optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "  # Функция обучения вернет ошибку на батче\n",
        "  return batch_loss"
      ],
      "metadata": {
        "id": "UNPrXmIqYHpN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Обучаем сеть. На каждой эпохе прогоняем весь набор данных через функцию обучения. Считаем лоссы.\n",
        "#Проверяем"
      ],
      "metadata": {
        "id": "6psy6MOPKvWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 5 # устанавливаем количество эпох\n",
        "\n",
        "for epoch in range(EPOCHS): # Цикл по каждой эпохе\n",
        "  start = time.time() # Запомним время начала эпохи\n",
        "\n",
        "  progbar = tf.keras.utils.Progbar(target=steps_per_epoch, stateful_metrics=[\n",
        "                                     'batch_loss'], unit_name='batch')        # Создадим индикатор прогресс обучения\n",
        "\n",
        "  enc_hidden = encoder.initialize_hidden_state() # Задаем начальное состояние на скрытом слое encodera \n",
        "  total_loss = 0                                 # Начальное значение итоговой ошибки\n",
        "\n",
        "  # Для батча, входного и выходного тензора на каждом шаге эпохи\n",
        "  for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
        "    batch_loss = train_step(inp, targ, enc_hidden) # Передадим в функцию тензоры и состояние в кодировщике, обучим и получим ошибку на батче\n",
        "    total_loss += batch_loss                       # Добавим ее в итоговую ошибку\n",
        "    progbar.update(                                # Обновим состояние индикатора обучения\n",
        "            batch + 1, values=[('batch_loss', batch_loss)])\n",
        "\n",
        "\n",
        "  # Каждые 5 эпох будем сохранять чекпоинты\n",
        "  if (epoch + 1) % 5 == 0:\n",
        "    checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "\n",
        "  # Выведем показатели после каждой эпохи\n",
        "  print('Эпоха {} Ошибка {:.4f}'.format(epoch + 1, total_loss / steps_per_epoch)) # Выведем номер эпохи и потери\n",
        "  print('Время на 1 эпоху {} сек'.format(round(time.time() - start), 1))          # Выведем длительность обучения этой эпохи"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "htnhnv6SYby4",
        "outputId": "42c5ee11-8766-4649-ca6a-d6446a10d7ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "250/250 [==============================] - 69s 276ms/batch - batch_loss: 0.1549\n",
            "Эпоха 1 Ошибка 0.1736\n",
            "Время на 1 эпоху 69 сек\n",
            "250/250 [==============================] - 68s 273ms/batch - batch_loss: 0.1255\n",
            "Эпоха 2 Ошибка 0.1298\n",
            "Время на 1 эпоху 68 сек\n",
            "250/250 [==============================] - 68s 273ms/batch - batch_loss: 0.0921\n",
            "Эпоха 3 Ошибка 0.1041\n",
            "Время на 1 эпоху 68 сек\n",
            "250/250 [==============================] - 68s 274ms/batch - batch_loss: 0.1287\n",
            "Эпоха 4 Ошибка 0.0890\n",
            "Время на 1 эпоху 69 сек\n",
            "250/250 [==============================] - 68s 274ms/batch - batch_loss: 0.0838\n",
            "Эпоха 5 Ошибка 0.0780\n",
            "Время на 1 эпоху 85 сек\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Данная функция собирает модель кодера, декодера и attention для работы в режиме перевода (предсказания).\n",
        "#На входе переводимое русское предложение, на выходе его английский перевод"
      ],
      "metadata": {
        "id": "YPjpYiKkKvcr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(sentence):\n",
        "\n",
        "    # Создаем начальные настройки графика внимания\n",
        "    attention_plot = np.zeros((max_length_targ, max_length_inp)) \n",
        "    \n",
        "    # Предобрабатываем предложение\n",
        "    sentence = preprocess_sentence(sentence) \n",
        "\n",
        "    inputs = [inp_language_tokenizer.word_index[i] for i in sentence.split(' ')]   # Преобразовываем в послед-ть индексов\n",
        "    inputs = pad_sequences([inputs], maxlen=max_length_inp, padding='post')        # Делаем паддинг\n",
        "    inputs = tf.convert_to_tensor(inputs)                                          # Конвертируем в тф тензор\n",
        "\n",
        "    result = ''                                                                    # Сюда запишем результат\n",
        "\n",
        "    hidden = [tf.zeros((1, units))]                                                # Задаем начальное состояние\n",
        "    enc_out, enc_hidden = encoder(inputs, hidden)                                  # Передаем его и входной тензор и получаем выход с кодера и состояние\n",
        "\n",
        "    dec_hidden = enc_hidden                                                        # Состояние кодера передаем в декодер\n",
        "    dec_input = tf.expand_dims([targ_language_tokenizer.word_index['<start>']], 0) # Передаем на вход декодеру <start> в виде индекса\n",
        "\n",
        "    for t in range(max_length_targ):                                               # Идем по макс.длине фраз выходного языка(анг)\n",
        "        # Прогоняем через декодер входящий тензор, состояние с выхода кодера, выход с кодера\n",
        "        # Получаем результат предсказания, обновленное состояние, и веса внимания\n",
        "        predictions, dec_hidden, attention_weights = decoder(dec_input, dec_hidden, enc_out)\n",
        "\n",
        "        # Сохраняем веса внимания для графика\n",
        "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
        "        attention_plot[t] = attention_weights.numpy()\n",
        "\n",
        "        # Аргмаксом вытаскиваем предсказанное слово\n",
        "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
        "\n",
        "        # Результат конвертируем из индекса в слово и сохраняем в result = ''\n",
        "        result += targ_language_tokenizer.index_word[predicted_id] + ' '\n",
        "\n",
        "        # Если предсказанное слово - <end>, то останавливаемся, возвращаем результаты, выводим на графике\n",
        "        if targ_language_tokenizer.index_word[predicted_id] == '<end>':\n",
        "            return result, sentence, attention_plot\n",
        "\n",
        "        # Педсказанное значение подается обратно в модель\n",
        "        dec_input = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "    # Вернем перевод, входную фразу и веса внимания\n",
        "    return result, sentence, attention_plot"
      ],
      "metadata": {
        "id": "sCTtfYH2cEry"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Нам интересно как связаны слова в исходной фразе и в ее переведе. \n",
        "#Функция отрисовывает веса внимания в виде 2D матрицы, соотносит каждую пару слов ее весом"
      ],
      "metadata": {
        "id": "Ps-7z6DxLLIY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_attention(attention,           # Веса внимания\n",
        "                   sentence,            # Исходная фраза\n",
        "                   predicted_sentence): # Предсказаные перевод\n",
        "  \n",
        "    fig = plt.figure(figsize=(10,10))                                   # Зададим размер \n",
        "    ax = fig.add_subplot(1, 1, 1)                                       # Добавим 1 картинку\n",
        "    ax.matshow(attention, cmap='viridis')                               # Нарисуем 2d матрицу\n",
        "    fontdict = {'fontsize': 14}                                         # Зададим размер надписей\n",
        "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90) # Добавим надпись по горизонтальной оси\n",
        "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)    # Добавим надпись по вертикальной оси\n",
        "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))               # Зададим форматирование делений на осях графиков\n",
        "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))               # Зададим форматирование делений на осях графиков\n",
        "    plt.show()                                                          # Отрисуем изображение"
      ],
      "metadata": {
        "id": "S2_sRUt_cTPW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Соберем написанные ранее функции вместе. Будем переводить фразы и строить матрицы внимания(attention) - смотреть связи слов в предложении"
      ],
      "metadata": {
        "id": "-119S1sdLLO1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Создадим функцию для перевода фраз с визуализацией матрицы внимания"
      ],
      "metadata": {
        "id": "4o_nXdrHLLRK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def translate(sentence): # Функция принимает предложение и выводит результат с визуализацией\n",
        "    result, sentence, attention_plot = evaluate(sentence)  # Отдадим фразу. Получим перевод, входную фразу,  веса внимания\n",
        "\n",
        "    print('Входящая фраза: %s' % (sentence))          # Выведем входную фразу \n",
        "    print('Предсказанный перевод: {}'.format(result)) # Выведем полученный перевод\n",
        "\n",
        "    attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))] # Возьмем весы внимания, только для слов во фразах. Хвосты не смотрим\n",
        "    plot_attention(attention_plot, sentence.split(' '), result.split(' '))              # Выведем веса внимания"
      ],
      "metadata": {
        "id": "keSyzu5qcgov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Воспроизведём последний сохранённый чекпоинт\n",
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xGt9jILeckAN",
        "outputId": "374552eb-f3bc-40c8-eb9f-0c9eb708d91a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fafc1f86d00>"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#И, наконец, переведём предложение и выведем визуализацию"
      ],
      "metadata": {
        "id": "R-6Fq-WYcxcN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "translate('давайте дружить')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 684
        },
        "id": "vXNMyJ4wckK4",
        "outputId": "a3215f10-c8e4-40a1-ed24-60125ef2dcf8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Входящая фраза: <start> давайте дружить <end>\n",
            "Предсказанный перевод: let s be friends . <end> \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "translate('у тебя всё хорошо')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 675
        },
        "id": "103iezpCckVW",
        "outputId": "a3713cb0-4124-4e99-c37d-9e928bf19bb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Входящая фраза: <start> у тебя всё хорошо <end>\n",
            "Предсказанный перевод: you re doing ok . <end> \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "translate('у тебя всё хорошо?')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 610
        },
        "id": "p1ehFzWNckYG",
        "outputId": "4c616ae9-0ba0-48d1-b11f-dacb76dfcbcc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Входящая фраза: <start> у тебя всё хорошо ? <end>\n",
            "Предсказанный перевод: are you ok ? <end> \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnUAAAIvCAYAAAAS4i3FAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3debhlZ1nn7++T2SQCQkIMyCxTCFOIAgZp6Mgg4sDQ2oxClDApDUjLLLYIiCA/EEUIIBJARpsGUUFGQcQfHUIzJU0YwmSYwhQyh9TTf6xd5HCoKlJVqbP2fs99X9e56uy1d516aufk7E+tvda7qrsDAMBq22vuAQAA2H2iDgBgAKIOAGAAog4AYACiDgBgAKIOAGAAog4AYACiDgBgAKIOAGAA+8w9AABU1WFJHp7kiCSd5JQkL+jur846GKwQe+qWVFVdt6reVVU3nnsWgD2pqo5J8ukk905yXpLzk9wnyaeq6tZzzgarpFz7dTlV1R8neUKS53X3o+aeB2BPqaoPJPlYkod095bFtr2SvDDJkd39c3POB6tC1C2hqqokn0vy9iS/nOQq3X3xrEMB7CFVdV6Sm3X3J9dtv0GSD3f3j80zGawWb78up9sl+fEkj0jyvSR3mXUagD3rO0mutY3t10ry7Q2eBVaWqFtOv5nkDd19bpLXLG4DjOo1SV5aVfepqmstPu6b5CVJXj3zbLAyvP26ZKrqoCRfTvJL3f2+qrpZkg8kOby7/YsVGE5V7ZfkWUkekktWZbgoyV8leWx3XzjXbLBKRN2Sqar7J/nD7r72mm0fzXRq/wvnmwxgz6qqA5NcZ3HzM4t3K2DDLHas3CPJm7r7O3PPs7O8/bp87pfkleu2vTLJAzZ+FICN093ndvfHFh+Cjjn8epKXZXotXjn21C2RqrpaktOT3LC7P7Vm+09lOhv2iO4+babxAPaIqnrzDu7u7v7VDRuGTa2q3p3ksCTndvfRc8+zs1xRYol09xezjf8m3f2lbW0HGMQ3trN970yLEMMeV1XXTHJMkp9N8u9VdUR3nzLrUDvJnrolU1VXT/LF3sZ/mKq6end/YYaxADZcVR2Q5Jzu3nvuWRhfVT05ye26+9iq+p9JPtXdj517rp3hmLrlc3qSQ9dvrKorLe4D2CzsdWAj3T/JKxafvyrJfRYXA1gZ3tJbPpVt/yA7ONP1EAGGUlVHbeeu/TZ0EDatqvq5JIcnecNi098neXGSX8h0daeVIOqWRFX9+eLTTvKMqlp75tfemd7j/z8bPhjAnndSpp9929orYm8dG+E3My1jcnaSdPeFVfW6TCtPiDp22o0Xv1aSGyZZu9jmhUlOTvLsjR4KYANs6xJhSXJAkpU6UJ3VU1X7Z1rK5F7r7nplkrdV1cFbY2/ZOVFiiSzeu39dkuO6+7tzzwMwp8WL7blOlGBPqqpDMl1j/ZXdvWXdffdN8o7u/sosw+0kUbdEqmrvTMfN3XTVTqMGuKyJOtg53n5dIt19cVV9Pg4OBjaRHSw+bIUG2Amibvk8NcmfVNV9u/vMuYcB2ADbW3w4SU7csCnYVKrq9FzKE3HWXo99mXn7dclU1ccyHTS8b5IvJTln7f3dfZM55gKAkVTV7625eXCSRyf5YJIPLLbdOtPKE3/W3X+0wePtEnvqls8bfvRDAMZTVddOckSmvSendvdnZx6JgXX3n239vKr+Jskzu/vpax9TVY9PcqMNHm2X2VMHJEmq6q93dH93H7dRs7C5VNXlkrw0yT2SbD37sJL8XZLfshoAe1pVnZXkqO7+9LrtP53k5O6+3DyT7RwHoQJbPSDJT2W6TN2hSe6b5BprbsOe8rwkN0ly+yQ/tvg4drHtuTPOxeZxTpLbbWP77ZKcu43tS8meuiVTVfsleWKmRRCvnunYuu9zaj97SlVtSfKT3f21xe3vZlpex1tg7FFV9Y0kv9bd71u3/bZJ3tjdV5pnMjaLqvr9TCcqvizJvy823yrTlSb+sLufOddsO8OeuuXz1EzfRH+W6W2I/57kLzOdHfawGedifBfmB5fT2Tc/vMI67Ak/lm2fAfvNTFeVgD2qu/80yf0yXd3pOYuPGyf5zVUJusSeuqWzOMX6od391sWekpt192eq6qFJju3ue848IoOqqlOTvLy7/6SqfiPTxay/lOTjSR7Y3efs8AvALqqqtyc5K8n9uvvcxbaDMi1ncrnuvsOc88GqEHVLpqrOTXKD7v5CVX05yV27+0NVda0kH1mVgzVZPVX1wEwhtyXJ3kmenOTPk7w80/fkypwBxmqpqiOTvC3JgUk+uth840zHMt2puz8x12xsPlV1hax7J7O7vznTODvFkibL5wtJrrL49dNJ7pTkQ5nWyzlvxrkYXHe/rKr+LdPB6ad390mLu+6xON4E9oju/nhVXTfJfZLcYLH5FUle1d1+7rHHVdU1krww04kRaw9DqUxL7KzE8ez21C2ZqnpGkrO7+2lVdc8kr870FthVkzyru58464AAMJiqeleSKyR5dpIzsu5KE939L3PMtbNE3ZKrqlsmOSbJad39lrnnYWyLC6jfJ5csAPuJJK/u7gtmHYzhVdVRSR6Z6XsvSU5N8v9198nzTcVmUVVnJ7lVd3987ll2h7Nfl0xV3baqvv+2eHf//939nCRvXZzeD5eJqtqnqr5QVYcubh+R5LRMZ33dMtPp/M9NclpV3WD7Xwl2T1XdJ8n/TnJ4kn9cfByW5INVdd85Z2PTOD3J/nMPsbvsqVsyVXVxksO3rhW2ZvuVknzNOnVclqrqO0lu3t2fXZyBeG6mMxDPWtx/uSSvTLJfd995xlFXQlXdOMmDk1wnyXHd/eWq+rUkn+/uD8873fKqqs8lOWE7l2h6cHdfc4652Dyq6j8neVySh62/qsQqsadu+Ww9KHO9K2Va8RouS1/PdMZhkvxckidsDbokWXz+xCS3mWG2pVdV91osvZGqumOmvU1XTfKfM629lkyB95R5JlwZhyZ53Ta2vz7JlTd4FjanN2U6SeKTVXVuVZ219mPm2S41Z78uiap68+LTTvLKqlp7DNPeSY5M8m8bPhij+3CSX8y0Ft23Mx0ovN7lMy1MzA97TpIPZPoH11OTPLq7X7BYY3Kr9yT5vRlmWyXvzvSCun4Pye2SrMQB6qy835l7gMuCqFseW1dTryTfyg8uX3Jhkn/NtIYYXJb+MsmbqurkJG9M8uKqelAuuUzOrZO8KMk/zDTfUuvuw9fcPDLTsWDrfTPJFTdmopX1T0meUVVH5wcv0XT3JH9YVXff+sDu/p8zzMfguvvlc89wWXBM3ZKpqqckebbV+9koi4PUn5/kgkwHp3emBYiT6RCNt2Y6zm4lFt/cSFX12iSP6O6vVtUXk/zX7n7/2uvmVtU9kjyzu3963mmX1+K6w5dGO66YPaWqDst0qbDrJHlyd59ZVcckOaO7T593ukvHnrrl89S1N6rqJ5PcNckp3e3tVy5z3f2qqvpfSX4+07FNW4+1/VaS/9vdp8023PL7ZpKLF5//bZJnVdWvZwrjfarqP2Va9+plM823Errb8d3MqqpukeSdmc6CvVGSZyU5M8kdklwvyb3nm+7Ss6duyVTVPyV5a3c/r6oOTvJ/kxyU5OAkv9XdJ846ILBNVbVvkr9J8l8zHUaxZfHr3yZ5QHdfvP3fDcypqt6d5L3d/ZR1e9pvneQ13X2NmUe8VPzraPkcneRdi8/vnuki11dO8qAkj5lrKDaHqnpYVX1icfbXtRfbHrfY+8QOdPdF3X2fJNdN8uuZ/mV/g+6+n6D70arql6rqvVV1ZlV9var+paruMvdcbBq3yHSd6/W+nOmwlJUg6pbPwZnOQkySOyZ5Y3dflCn0rjPbVAyvqh6Z5ElJTsi0h2mr/8ggZ4btSVW1X1Ud0N2f7e43dPfruvtTVXVAVe33o7/C5lVVv53pRJ3PJHlspvXCTk/yxqo6bs7Z2DTOS/IT29h+gyRf28b2pSTqls8XkhyzWPvqTknevth+xUwLw8Ke8pAkD+ru5yX53prtJ2c6xoQde32Sh21j+0Oy7TXYuMRjMy0H88Dufuni4wGZ3p143LyjsUm8KclTFpdKTJKuqmsmeWaSv5trqJ0l6pbPc5K8IsmXMu0hee9i+22TfGyuodgUrpFpvbr1LsolC+myfcck+edtbH97poWd2b6rZzrLer1/yvR9CXvaYzLtPNm6IPu/Zlo38TuZ3sFYCc5+XTLd/aKqOinTD7m3d/fWU/0/k+TJ803GJvDZJEcl+fy67XdJcsrGj7NyDswP7uHcakuSH9/gWVbNFzKdZbh+8eE75oe/H+Eyt7h6zm0Wlws7KtNOr5O7+x3zTrZzRN0SqarLJ7lJd78vyYfW3f3teGFlz3p2kr+oqgMzHVN366q6X5LfT+K4ph/to0nulR++JNi9s+09oFzi2UmeX1VH5ZIr5xyTac2w351tKjaFta+93f2uXHKyYhbr1J3S3d+abcCdYEmTJVJVP57pTJs7dff712y/aZIPJrlqd58513yMb3E1iScludpi0xlJntLdL51vqtWwOFPzTZmOn9v6onBskv+S5G7d/Za5ZlsFVXW3TJdTu+Fi06lJntXdb5pvKjaDkV57Rd2SqapXJTm7ux+8Ztuzk1yvu39lvsmW32IB3Zck+cc1b1tzKVXVu5Lcvbu/XVWHJNmru1fmrK9lUFV3zhTFN19s+nCSp3X3P8031fKrqnt09zYPRq+qx3b3Mzd6JjaXUV57nSixfE5M8l+2LoFQVXtlevvmb+YcakWck+S1Sb5UVU+vquvOPdCKuV2S/ZKku88UdLvk7d19m+4+KMk1M5349IV5R1oJr6yql1TV90/IqaqfWiwI+6gZ52LzGOK1V9Qtn7dnWi/nrovbx2Z6of372SZaEYuFXw/PdKm1X0jyycVipvdf+2LBDtl1v4sWF50/q6rOqKpjMx0D+7okH1kcm8j23TLJrTI9V0dX1W9kOkbx/CQ3nXWyFVBVd62qRy4uK8muGeK119uvS6iqnpnk+t39a1V1YpLvdvfD555r1VTVjZL8dqZ1wi7ItBfvud196qyDLanFRdVfm+kH2w/pbidL7EBVfSzTMghfTfKIJH+e5I+SPDrJA7vbWn87UFUHJHlBppMjOsljuvvP551q+VXV4zL9Q/ZrmU5+/IXutvzVLhjhtdeeuuV0YpI7V9XVk9wt2750CTtQVVdJ8quZ/tX1vUyLR14tyUeryuXWtq928MGOXTfJn2R6gT04yWsXx3a+Nsm15xxsRdw0yX/KtKzJhUl+dnEAOzv2sEzXBb9qkucleXtV3bGqrl5V+1TV4YvXEn60lX/ttaduSS3WqjsvySHdfcMf9Xi+f0H1X820/MYdMh2k/uIkr+7usxeP+ZUkJ3b3FWYbdElV1cVJDncs3a5Z7Ok8rLu/vrgg+E26+/SqOizJGd2998wjLq2q+oMkT0zyl5muIHGtJK9KckiS+y2WeWIbqursJEd29+cWt5+U5H8s7v6ZTM/j9Xz/XTqr/tprnbrldWKS52b6Qcel8+VMe5T+Nsnjuvuj23jMe5OsxHpDM7A3bvc9o6rOzXQszh9W1XcyLUrMjj0kyS9399Yrcnyyqm6V5I+TvCPJ/tv9nZyW5Igkn0uS7v7jqnpppuOLT01y//ge3Bkr/dprT92SqqorZlp080Xd/ZW551kFi4PRX9/d5889yyqqqpcleUR3f3fuWVZRVb0nOzjRpLtvv3HTrJaqOmR764BV1W27+73buo+kqn4nye27+x5zzzKCVX/tFXUAAANwogQAwABEHQDAAETdkquq4+eeYZV5/nad5273eP52j+dv93j+dt0qP3eibvmt7DfXkvD87TrP3e7x/O0ez9/u8fztupV97kQdAMAANv3Zr/vVAX1AHTT3GNt1UZ+ffeuAucfYviX//rkoF2TfJV3iassVlnvpqO9dcE722X95/9/Y6zvnzj3CDl3UF2TfWs7vvSRLf5XfZf5/93o3We7vvST5+jcuzqFXWs71hk/76HL/7Fvm770k+W6+dWZ3H7qt+zb94sMH1EG51b53nnuMldXfu2juEVbWebf/mblHWGkHvuXkuUdYaX3xxXOPsLLe9rYPzz3CSrvTVW8+9wgr7R1bXv/57d3n7VcAgAGIOgCAAYg6AIABiDoAgAGIOgCAAYg6AIABiDoAgAGIOgCAAYg6AIABiDoAgAGIOgCAAYg6AIABiDoAgAGIOgCAAYg6AIABiDoAgAGIOgCAAYg6AIABiDoAgAGIOgCAAYg6AIABiDoAgAGIOgCAAYg6AIABiDoAgAGIOgCAAYg6AIABiDoAgAGIOgCAAYg6AIABiDoAgAGIOgCAAYg6AIABiDoAgAGIOgCAAax81FXVvnPPAAAwt6WLuqq6c1W9r6q+VVXfrKq3VdUNF/dds6q6qu5VVe+qqvOSPHhx3wOr6pSqOr+qTquqR1XV0v39AAD2hH3mHmAbDkry3CQfTfJjSZ6U5O+r6og1j3lGksck+a0kF1XVg5L8UZLfTfKhJEcmeXGSi5L8xcaNDgAwj6WLuu7+u7W3q+qBSc5K8rNJvrTY/PzufsOaxzw5ye+v2XZ6Vf1JkodlG1FXVccnOT5JDsiBl/nfAQBgoy1d1FXVdZI8Ncktkxya6S3ivZJcPZdE3UlrHn9okqsleVFV/dWaL7VPktrWn9HdJyQ5IUkut9eV+jL+KwAAbLili7okb8kUbw9O8h9JvpfklCT7rXnMOWs+33rc3EOS/NtGDAgAsGyWKuqq6kpJbpDkYd397sW2o7KDObv7q1V1RpLrdPeJGzMpAMByWaqoS/KtJGcmeVBVfTHJVZM8K9Peuh15SpLnV9W3k/xjkn2THJXkqt39jD04LwDAUliqJT+6e0uS30hykyQfT/KXSZ6c5IIf8ftekuS4JPdL8pEk78t0IsTpe3JeAIBlsWx76tLd78q0JMlaB6/5fHsnP7w6yav31FwAAMtsqfbUAQCwa0QdAMAARB0AwABEHQDAAEQdAMAARB0AwABEHQDAAEQdAMAARB0AwABEHQDAAEQdAMAARB0AwABEHQDAAEQdAMAARB0AwABEHQDAAEQdAMAARB0AwABEHQDAAEQdAMAARB0AwABEHQDAAEQdAMAARB0AwABEHQDAAEQdAMAARB0AwABEHQDAAEQdAMAARB0AwABEHQDAAEQdAMAA9pl7gLlVVeqA/eceY3WdP/cAq+vcQ/eee4SVdvA1rzb3CCutD/Rzb1fd6ANHzD3CSrv6gZ+be4TVdvb277KnDgBgAKIOAGAAog4AYACiDgBgAKIOAGAAog4AYACiDgBgAKIOAGAAog4AYACiDgBgAKIOAGAAog4AYACiDgBgAKIOAGAAog4AYACiDgBgAKIOAGAAog4AYACiDgBgAKIOAGAAog4AYACiDgBgAKIOAGAAog4AYACiDgBgAKIOAGAAog4AYACiDgBgAKIOAGAAog4AYACiDgBgAKIOAGAAog4AYACiDgBgAKIOAGAAog4AYACiDgBgAKIOAGAAs0ddVd2/qr5RVfuv2/6qqnrz4vMHV9Wnq+rCxa8PWvfYrqp7rtv2uap6zJ7/GwAAzG/2qEvy+kxz/OrWDVV1+SR3S/LSqrpbkr9I8twkRyZ5XpIXVNUvzzArAMBS2mfuAbr7vKp6VZLjkrxusfneSc5K8g9J/iXJK7r7Lxb3nVZVt0jy2CR/vyt/ZlUdn+T4JDmgDtqN6QEAlsMy7KlLkhcnuUNV/dTi9nFJXt7d30tywyTvX/f4f01yxK7+Yd19Qncf3d1H71cH7OqXAQBYGksRdd39kSQnJ3lAVR2Z5Ogkf/2jftu6z2vd/ftedhMCACy3pYi6hRcneUCS307y/u7+5GL7qUmOWffY2yQ5Zc3tryc5fOuNqjps7W0AgNHNfkzdGq9O8pwkD03ykDXbn5Xk9VX1oST/nOTOSe6T5O5rHvOuJA+vqn9LcnGSpyc5fyOGBgBYBkuzp667v5vpRIkLcskJE+nu/5Xkd5M8KtPeuf+W5GHdvfYkid9L8tkk70nyhiQvSfK1DRkcAGAJLNOeumR6y/S13X3O2o3d/cIkL9zeb+ruM5L84rrNf3fZjwcAsJyWIuqq6ieS/HySOya56czjAACsnKWIuiQfTnLFJE/o7o/PPQwAwKpZiqjr7mvOPQMAwCpbmhMlAADYdaIOAGAAog4AYACiDgBgAKIOAGAAog4AYACiDgBgAKIOAGAAog4AYACiDgBgAKIOAGAAog4AYACiDgBgAKIOAGAAog4AYACiDgBgAKIOAGAAog4AYACiDgBgAKIOAGAAog4AYACiDgBgAKIOAGAAog4AYACiDgBgAKIOAGAAog4AYACiDgBgAKIOAGAA+8w9wOz2qtR++849xcrq886be4SVdcjffGjuEVbaxTe//twjrLS9v+P/3V119Qf8x9wjrLRvvO4qc4+w2u6y/bvsqQMAGICoAwAYgKgDABiAqAMAGICoAwAYgKgDABiAqAMAGICoAwAYgKgDABiAqAMAGICoAwAYgKgDABiAqAMAGICoAwAYgKgDABiAqAMAGICoAwAYgKgDABiAqAMAGICoAwAYgKgDABiAqAMAGICoAwAYgKgDABiAqAMAGICoAwAYgKgDABiAqAMAGICoAwAYgKgDABiAqAMAGICoAwAYgKgDABiAqAMAGMAQUVdVt6uqrqpD5p4FAGAOQ0QdAMBmJ+oAAAawMlFXVftX1XOr6qtVdX5V/XtV3WYHj31jVZ1cVVfe6FkBADbaykRdkj9N8htJjkty8yQfS/LWqjp87YOq6nJJ3prkiklu191f2+hBAQA22kpEXVUdlOShSR7b3f/Q3acmeUiSryZ5+JqHXjnJu5N8N8mduvus7Xy946vqpKo66cIt5+/h6QEA9ryViLok10myb5L3b93Q3Rcn+UCSI9Y87m1JvpTk7t293Vrr7hO6++juPnq/vQ7YQyMDAGycVYm6Hek1n78lyW2SHDnTLAAAs1iVqPtMkguTHLN1Q1XtneTWSU5Z87gnJ3lhkndW1c02dEIAgBntM/cAl0Z3n1NVf5XkmVV1ZpLTkzwqyWFJXpDk+mse+8SqqiTvqKpju/sjswwNALCBViLqFh67+PVlSa6Q5MNJ7tzdX66q6699YHc/YRF27xR2AMBmsDJR190XJHnk4mP9fe9JUuu2PT7J4zdkOACAma3KMXUAAOyAqAMAGICoAwAYgKgDABiAqAMAGICoAwAYgKgDABiAqAMAGICoAwAYgKgDABiAqAMAGICoAwAYgKgDABiAqAMAGICoAwAYgKgDABiAqAMAGICoAwAYgKgDABiAqAMAGICoAwAYgKgDABiAqAMAGICoAwAYgKgDABiAqAMAGICoAwAYgKgDABiAqAMAGICoAwAYgKgDABiAqAMAGMA+cw8wuy2dPu/8uadYWb2l5x5hdW25cO4JVttJp8w9wUq7uLfMPcLqaj/3dschjz5s7hGGZU8dAMAARB0AwABEHQDAAEQdAMAARB0AwABEHQDAAEQdAMAARB0AwABEHQDAAEQdAMAARB0AwABEHQDAAEQdAMAARB0AwABEHQDAAEQdAMAARB0AwABEHQDAAEQdAMAARB0AwABEHQDAAEQdAMAARB0AwABEHQDAAEQdAMAARB0AwABEHQDAAEQdAMAARB0AwABEHQDAAEQdAMAARB0AwABEHQDAAEQdAMAARB0AwABEHQDAAIaKuqr6nar6cFWdU1VfrKrHzz0TAMBG2GfuAS5jxyb5gySfSHLbJC+pqk9095vnHQsAYM8aKuq6+25rbn62qp6e5KfnmgcAYKMM9fbrWlX1hCT7JnnN3LMAAOxpQ+2p26qqnpTkEUnu0N1nbOP+45McnyQH1EEbPB0AwGVvuKirqqsk+aMkv9Td/2dbj+nuE5KckCSX3/uQ3sDxAAD2iBHffj08SSU5de5BAAA2yohRd2qSn0nyQ2+7AgCMasSoOzLJK5McOvcgAAAbZcSoOzDJ9TOd+QoAsCkMd6JEd78n0zF1AACbxoh76gAANh1RBwAwAFEHADAAUQcAMABRBwAwAFEHADAAUQcAMABRBwAwAFEHADAAUQcAMABRBwAwAFEHADAAUQcAMABRBwAwAFEHADAAUQcAMABRBwAwAFEHADAAUQcAMABRBwAwAFEHADAAUQcAMABRBwAwAFEHADAAUQcAMABRBwAwAFEHADAAUQcAMABRBwAwAFEHADAAUQcAMABRBwAwgH3mHmBuvWVLtpx77txjADtry8VzTwDsgos/+em5RxiWPXUAAAMQdQAAAxB1AAADEHUAAAMQdQAAAxB1AAADEHUAAAMQdQAAAxB1AAADEHUAAAMQdQAAAxB1AAADEHUAAAMQdQAAAxB1AAADEHUAAAMQdQAAAxB1AAADEHUAAAMQdQAAAxB1AAADEHUAAAMQdQAAAxB1AAADEHUAAAMQdQAAAxB1AAADEHUAAAMQdQAAAxB1AAADEHUAAAMQdQAAAxB1AAADEHUAAAMQdQAAA1iZqKuqx1TV5+aeAwBgGa1M1AEAsH2XSdRV1eWq6gqXxdfaiT/z0Ko6YCP/TACAZbXLUVdVe1fVnarqb5N8JclNF9svX1UnVNXXquq7VfUvVXX0mt/3gKo6u6qOraqPV9U5VfXuqrrWuq//+1X1lcVjT0xy8LoR7pLkK4s/65hd/XsAAIxgp6Ouqm5UVX+a5ItJXpvknCR3TvLeqqok/5DkqknumuTmSd6b5F1VdfiaL7N/kscnOS7JrZNcIckL1/wZv57kj5M8JclRST6Z5NHrRnlVknsn+fEkb6+qT1fVH6yPQwCAzeBSRV1VXamqHlFVH0ry4SQ3SPLfkvxkdz+ou9/b3Z3k9kluluSe3f3B7v50dz85yWeT3G/Nl9wnycMXj/lokmcnud0iCpPkkUle3t0v6u7TuvtpST64dqbu/l53/2N33yvJTyZ5+uLP/1RVvaeqjquq9Xv3tv59jq+qk6rqpItywaV5CgAAltql3VP3u0mel+T8JNfr7l/p7td39/nrHneLJAcm+fribdOzq+rsJEcmuc6ax13Q3b81l9IAAASKSURBVJ9cc/uMJPsl+YnF7Rsm+cC6r73+9vd191nd/dfdffskP5PksCQvTXLP7Tz+hO4+uruP3jf77+CvDQCwGva5lI87IclFSe6f5ONV9cYkr0jyzu6+eM3j9kry1SQ/v42vcdaaz7+37r5e8/t3WlXtn+nt3vtmOtbuE5n29r1pV74eAMCquVQR1d1ndPfTuvv6SX4hydlJXpPkS1X1Z1V1s8VDT860l2zL4q3XtR9f24m5Tk1yq3XbfuB2TW5TVS/KdKLG85N8Osktuvuo7n5ed39rJ/5MAICVtdN7xrr737v7oUkOz/S27PWS/O+q+vkk70jy/iRvqqpfrKprVdWtq+p/LO6/tJ6X5Der6kFVdd2qenySW657zH2T/HOSyyW5V5Krdfd/7+6P7+zfCQBg1V3at19/SHdfkOQNSd5QVVdOcnF3d1XdJdOZqy9OcuVMb8e+P8mJO/G1X1tV107ytEzH6L05yXOSPGDNw96Z6USNs374KwAAbC41nbS6eV2urti3rGPnHgMA4Ed6R7/hQ9199Lbuc5kwAIABiDoAgAGIOgCAAYg6AIABiDoAgAGIOgCAAYg6AIABiDoAgAGIOgCAAYg6AIABiDoAgAGIOgCAAYg6AIABiDoAgAGIOgCAAYg6AIABiDoAgAGIOgCAAYg6AIABiDoAgAGIOgCAAYg6AIABiDoAgAGIOgCAAYg6AIABiDoAgAGIOgCAAYg6AIABiDoAgAGIOgCAAYg6AIABiDoAgAGIOgCAAYg6AIABiDoAgAGIOgCAAYg6AIABiDoAgAGIOgCAAYg6AIABiDoAgAGIOgCAAYg6AIABiDoAgAGIOgCAAYg6AIABiDoAgAGIOgCAAYg6AIABiDoAgAGIOgCAAYg6AIABiDoAgAGIOgCAAYg6AIABiDoAgAGIOgCAAYg6AIABiDoAgAGIOgCAAYg6AIABiDoAgAGIOgCAAYg6AIABiDoAgAGIOgCAAYg6AIABiDoAgAGIOgCAAYg6AIABiDoAgAGIOgCAAewz9wBzqKrjkxyfJAfkwJmnAQDYfZtyT113n9DdR3f30ftm/7nHAQDYbZsy6gAARiPqAAAGIOoAAAYg6gAABiDqAAAGIOoAAAYg6gAABiDqAAAGIOoAAAYg6gAABiDqAAAGIOoAAAYg6gAABiDqAAAGIOoAAAYg6gAABiDqAAAGIOoAAAYg6gAABiDqAAAGIOoAAAYg6gAABiDqAAAGIOoAAAYg6gAABiDqAAAGIOoAAAYg6gAABiDqAAAGIOoAAAYg6gAABiDqAAAGIOoAAAYg6gAABiDqAAAGIOoAAAYg6gAABiDqAAAGUN099wyzqqqvJ/n83HPswCFJzpx7iBXm+dt1nrvd4/nbPZ6/3eP523XL/txdo7sP3dYdmz7qll1VndTdR889x6ry/O06z93u8fztHs/f7vH87bpVfu68/QoAMABRBwAwAFG3/E6Ye4AV5/nbdZ673eP52z2ev93j+dt1K/vcOaYOAGAA9tQBAAxA1AEADEDUAQAMQNQBAAxA1AEADOD/AZICRByulYDXAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FoEJwRVAL3PZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}