{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1YZ8VoAxmruT"
      },
      "source": [
        "Дорогой студент! \n",
        "\n",
        "В домашнем задании Lite вам предлагается поработать подробнее с параметрами словаря и формированием гиперпараметров нейронной сети. Создайте 9 нейросетей с различными гиперпараметрами (см. пунтк 2 и 3)\n",
        "\n",
        " Для этого необходимо:\n",
        "\n",
        "  1. Воссоздать ноутбук, аналогичный ноутбуку теоретической части, загрузив при этом необходимую нам базу (код уже доступен в ноутбуке).\n",
        "\n",
        "  2. Задать в ноутбуке следующие параметры для размера словаря, ширины окна и шага:\n",
        "\n",
        "    - Размер словаря - от 10000 до 20000 (выбрать меньшее значение диапазона, если будет перегрузка ОЗУ и перезапуск подключения к Colaboratory)\n",
        "    - Ширина окна - от 1000 до 2000\n",
        "    - Шаг - от 100 до 500 (на обучение лучше влияет наименьший шаг, но это может перегрузить ОЗУ).\n",
        "\n",
        "  3. Создать архитектуру сети и задать гиперпараметры. Можно воспользоваться шаблоном:\n",
        "  \n",
        "   - Добавьте модель прямого распространения **Sequential()**\n",
        "   - Добавьте один или несколько полносвязных (**Dense**) слоёв\n",
        "   - Добавьте слои **Dropout()** и **BatchNormalization()**\n",
        "   - Добавьте выходной полносвязный слой с количеством нейронов, соответствующим количеству классов (число писателей)\n",
        "  \n",
        "   Напомним, что точность сети можно проверить по значению показателя 'val_accuracy' на конце каждой эпохи. \n",
        "   "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Подготовка"
      ],
      "metadata": {
        "id": "bl5qdneKGvkp"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ky1AgGdguwwb"
      },
      "source": [
        "**Шаг 1**. Загрузка бибилиотек и базы данных.\n",
        "\n",
        "Подключаем необходимые библиотеки и модули:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2_tU14GmA7r"
      },
      "source": [
        "# Работа с массивами данных\n",
        "import numpy as np \n",
        "\n",
        "# Функции-утилиты для работы с категориальными данными\n",
        "from tensorflow.keras import utils\n",
        "\n",
        "# Класс для конструирования последовательной модели нейронной сети\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "# Основные слои\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, Activation \n",
        "\n",
        "# Токенизатор для преобразование текстов в последовательности\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "# Матрица ошибок классификатора\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "# Работа с google диском\n",
        "from google.colab import drive\n",
        "\n",
        "# Загрузка датасетов из облака google\n",
        "import gdown\n",
        "\n",
        "# Функции операционной системы\n",
        "import os\n",
        "\n",
        "# Регулярные выражения\n",
        "import re"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S4WZ_WpXwkMb"
      },
      "source": [
        "Потом загружаем датасет с текстами писателей в виде архива и распаковываем его в папку:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvMwi3yb_qRN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9e91e5e-8e4a-4c2b-a6bf-5ba5ab4ce132"
      },
      "source": [
        "# Загрузка датасета из облака\n",
        "gdown.download('https://storage.yandexcloud.net/aiueducation/Content/base/l7/writers.zip', None, quiet=True)\n",
        "\n",
        "# Распаковка архива в папку writers\n",
        "!unzip -qo writers.zip -d writers/\n",
        "\n",
        "# Просмотр содержимого папки\n",
        "!ls writers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'(Булгаков) Обучающая_5 вместе.txt'\n",
            "'(Булгаков) Тестовая_2 вместе.txt'\n",
            "'(Клиффорд_Саймак) Обучающая_5 вместе.txt'\n",
            "'(Клиффорд_Саймак) Тестовая_2 вместе.txt'\n",
            "'(Макс Фрай) Обучающая_5 вместе.txt'\n",
            "'(Макс Фрай) Тестовая_2 вместе.txt'\n",
            "'(О. Генри) Обучающая_50 вместе.txt'\n",
            "'(О. Генри) Тестовая_20 вместе.txt'\n",
            "'(Рэй Брэдберри) Обучающая_22 вместе.txt'\n",
            "'(Рэй Брэдберри) Тестовая_8 вместе.txt'\n",
            "'(Стругацкие) Обучающая_5 вместе.txt'\n",
            "'(Стругацкие) Тестовая_2 вместе.txt'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v3lnuZ2XxDjf"
      },
      "source": [
        "Сохраните в отдельных переменных:\n",
        "\n",
        "   - Имя для папки с текстами\n",
        "   - Название выборки \"обучающая\"\n",
        "   - Название выборки \"тестовая\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0o6vKYPJxECB"
      },
      "source": [
        "# Папка с текстовыми файлами\n",
        "FILE_DIR  = 'writers'\n",
        "\n",
        "# Признак обучающей выборки в имени файла                     \n",
        "SIG_TRAIN = 'обучающая'\n",
        "\n",
        "# Признак тестовой выборки в имени файла                   \n",
        "SIG_TEST  = 'тестовая'                    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "edtkKOhDx9dw"
      },
      "source": [
        "**Шаг 2.** Преобразование базы данных для обучения.\n",
        "\n",
        "Добавляем имена всех писателей в список классов.\n",
        "\n",
        "Воспроизводим блок кода, где преобразуем тексты в одну длинную строку и разбиваем их отдельно в списки для каждого класса и выборки."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wa_wqREXx2M7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c993845c-14f3-4b09-eb0a-df7e33c822e9"
      },
      "source": [
        "# В список добавляются имена классов\n",
        "CLASS_LIST = []\n",
        "\n",
        "# Здесь сохраняются тексты для обучения сети\n",
        "text_train = []\n",
        "\n",
        "# А здесь для проверки точности сети\n",
        "text_test = []\n",
        " \n",
        "# цикл для итерации по каждому имени текста в общей папке\n",
        "for file_name in os.listdir(FILE_DIR):\n",
        "\n",
        "    # Выделение имени класса и типа выборки из имени файла\n",
        "    m = re.match('\\((.+)\\) (\\S+)_', file_name)\n",
        "\n",
        "    # Если выделение получилось, то файл обрабатывается\n",
        "    if m:\n",
        "\n",
        "        # отдельно берём имя класса (автора)\n",
        "        class_name = m[1]\n",
        "\n",
        "        # отдельно - имя выборки lower не с заглавной буквы\n",
        "        subset_name = m[2].lower()\n",
        "\n",
        "        # Проверка типа выборки по названию в имени файла\n",
        "        is_train = SIG_TRAIN in subset_name\n",
        "        is_test = SIG_TEST in subset_name\n",
        "\n",
        "        # Если тип выборки обучающая или тестовая - файл обрабатывается\n",
        "        if is_train or is_test:\n",
        "\n",
        "            # Добавление нового класса, если его еще нет в списке\n",
        "            if class_name not in CLASS_LIST:\n",
        "\n",
        "                # Выводится информационное сообщение о добавлении названия класса\n",
        "                CLASS_LIST.append(class_name)\n",
        "\n",
        "                # Инициализация соответствующих классу строк текста\n",
        "                text_train.append('')\n",
        "                text_test.append('')\n",
        "\n",
        "            # Поиск индекса класса для добавления содержимого файла в выборку\n",
        "            cls = CLASS_LIST.index(class_name)\n",
        "\n",
        "            # Выводится информационное сообщение о добавлении класса в список классов и текста к выборке\n",
        "            print(f'Добавление файла \"{file_name}\" в класс \"{CLASS_LIST[cls]}\", {subset_name} выборка.')\n",
        "\n",
        "            # оператор with - безопасное чтение каждого файла с текстом\n",
        "            with open(f'{FILE_DIR}/{file_name}', 'r') as f:\n",
        "\n",
        "                # Загрузка содержимого файла в строку\n",
        "                text = f.read()\n",
        "\n",
        "            # Определение выборки, куда будет добавлено содержимое\n",
        "            subset = text_train if is_train else text_test\n",
        "\n",
        "            # Добавление текста к соответствующей выборке класса. Концы строк заменяются на пробел\n",
        "            subset[cls] += ' ' + text.replace('\\n', ' ')\n",
        "            \n",
        "# Определим кол-во классов\n",
        "CLASS_COUNT = len(CLASS_LIST)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Добавление файла \"(О. Генри) Тестовая_20 вместе.txt\" в класс \"О. Генри\", тестовая выборка.\n",
            "Добавление файла \"(Клиффорд_Саймак) Обучающая_5 вместе.txt\" в класс \"Клиффорд_Саймак\", обучающая выборка.\n",
            "Добавление файла \"(Клиффорд_Саймак) Тестовая_2 вместе.txt\" в класс \"Клиффорд_Саймак\", тестовая выборка.\n",
            "Добавление файла \"(Рэй Брэдберри) Обучающая_22 вместе.txt\" в класс \"Рэй Брэдберри\", обучающая выборка.\n",
            "Добавление файла \"(Булгаков) Тестовая_2 вместе.txt\" в класс \"Булгаков\", тестовая выборка.\n",
            "Добавление файла \"(Рэй Брэдберри) Тестовая_8 вместе.txt\" в класс \"Рэй Брэдберри\", тестовая выборка.\n",
            "Добавление файла \"(Макс Фрай) Обучающая_5 вместе.txt\" в класс \"Макс Фрай\", обучающая выборка.\n",
            "Добавление файла \"(Стругацкие) Тестовая_2 вместе.txt\" в класс \"Стругацкие\", тестовая выборка.\n",
            "Добавление файла \"(О. Генри) Обучающая_50 вместе.txt\" в класс \"О. Генри\", обучающая выборка.\n",
            "Добавление файла \"(Макс Фрай) Тестовая_2 вместе.txt\" в класс \"Макс Фрай\", тестовая выборка.\n",
            "Добавление файла \"(Стругацкие) Обучающая_5 вместе.txt\" в класс \"Стругацкие\", обучающая выборка.\n",
            "Добавление файла \"(Булгаков) Обучающая_5 вместе.txt\" в класс \"Булгаков\", обучающая выборка.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6KFkTkYyq1y"
      },
      "source": [
        "Подготовьте текстовую инфрмацию для обработки Токенайзером. Для этого сохраните в подходящих именах переменных следующие параметры:\n",
        "\n",
        "   - Объем словаря для токенизатора\n",
        "   - Длина отрезка текста (окна) в словах\n",
        "   - Шаг смещения окна по тексту для деления на векторы\n",
        "\n",
        "И затем вызовите сам Токенайзер, передав в его параметры эти переменные и оставшиеся значения для преобразования."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OruBwLqkyrLt"
      },
      "source": [
        "# Объем словаря для токенизатора\n",
        "VOCAB_SIZE = 15000\n",
        "\n",
        "# Длина отрезка текста (окна) в словах                        \n",
        "WIN_SIZE   = 3000\n",
        "\n",
        "# Шаг окна разбиения текста на векторы                         \n",
        "WIN_HOP    = 300                          \n",
        "\n",
        "# Токенайзер из Keras для разбиения текста и построения частотного словаря\n",
        "tokenizer = Tokenizer(num_words=VOCAB_SIZE, filters='!\"#$%&()*+,-–—./…:;<=>?@[\\\\]^_`{|}~«»\\t\\n\\xa0\\ufeff', \n",
        "                          lower=True, split=' ', oov_token='неизвестное_слово', char_level=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NS7TUrrz1M-9"
      },
      "source": [
        "Отдельно обучите сам Токенайзер на выборке текстов для обучения сети:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "skrycupq1Moi"
      },
      "source": [
        "# Получаем словарь частотности \n",
        "tokenizer.fit_on_texts(text_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n4YC49gT-284"
      },
      "source": [
        "Преобразуйте обучающие и проверочные тексты в последовательность индексов согласно частотному словарю Токенайзера:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6V1IUpSY-_4M"
      },
      "source": [
        "seq_train = tokenizer.texts_to_sequences(text_train)\n",
        "seq_test = tokenizer.texts_to_sequences(text_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56gEAIUZ1eQ6"
      },
      "source": [
        "**Шаг 3.** Создание функций для формирования выборок. Формирование выборок.\n",
        "\n",
        "Воспроизведите блок кода с двумя функциями:\n",
        "\n",
        "  1. Функция деления последовательности индексов на отрезки скользящим окном"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxJIXy9E1dv2"
      },
      "source": [
        "def split_sequence(sequence,   # Последовательность индексов\n",
        "                   win_size,   # Размер окна для деления на примеры\n",
        "                   hop):       # Шаг окна\n",
        "\n",
        "    # Последовательность разбивается на части до последнего полного окна\n",
        "    return [sequence[i:i + win_size] for i in range(0, len(sequence) - win_size + 1, hop)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hGSCHmlyOXhc"
      },
      "source": [
        " 2. Функция формирования выборок из индексов и соответствующих классам меток в формате One Hot Encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-s7ZBCCOYg6"
      },
      "source": [
        "def vectorize_sequence(seq_list,    # Список последовательностей индексов \n",
        "                       win_size,    # Размер окна для деления на примеры\n",
        "                       hop):        # Шаг окна\n",
        "\n",
        "    # В списке последовательности следуют в порядке их классов (их кол-во сповпадает с кол-вом классов)\n",
        "    class_count = len(seq_list)\n",
        "\n",
        "    # Списки для исходных векторов и категориальных меток класса\n",
        "    x, y = [], []\n",
        "\n",
        "    # Для каждого класса:\n",
        "    for cls in range(class_count):\n",
        "\n",
        "        # Разбиение последовательности класса cls на отрезки\n",
        "        vectors = split_sequence(seq_list[cls], win_size, hop)\n",
        "\n",
        "        # Добавление отрезков в выборку\n",
        "\n",
        "        x += vectors\n",
        "        \n",
        "        # Для всех отрезков класса cls добавление меток класса в виде OHE\n",
        "        y += [utils.to_categorical(cls, class_count)] * len(vectors)\n",
        "\n",
        "    # Возврат результатов как numpy-массивов\n",
        "    return np.array(x), np.array(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X6UIcMij2v6Y"
      },
      "source": [
        "Сформируйте выборки (x_train, y_train) и (x_test, y_test) с помощью функций, воспроизведённых в ячейке выше:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-TlOfvwa2vgc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00db6add-ea36-41a0-87fe-aadbf7eef630"
      },
      "source": [
        "# Формирование обучающей выборки\n",
        "x_train, y_train = vectorize_sequence(seq_train, WIN_SIZE, WIN_HOP) \n",
        "# Формирование тестовой выборки\n",
        "x_test, y_test = vectorize_sequence(seq_test, WIN_SIZE, WIN_HOP)\n",
        "\n",
        "# Проверка формы сформированных данных\n",
        "print(x_train.shape, y_train.shape)\n",
        "print(x_test.shape, y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5842, 3000) (5842, 6)\n",
            "(2190, 3000) (2190, 6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jiiOXgiX3UFK"
      },
      "source": [
        "Сформируем выборки индексов слов в виде матриц Bag Of Words методом  **sequences_to_matrix( )**. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TvpEhEXm36F3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da7b3af4-ab9e-4b37-8c80-47a32931c7f3"
      },
      "source": [
        "# На входе .sequences_to_matrix() ожидает список, .tolist() выполняет преобразование к типу данных 'список'\n",
        "x_train_01 = tokenizer.sequences_to_matrix(x_train.tolist())\n",
        "x_test_01 = tokenizer.sequences_to_matrix(x_test.tolist())\n",
        "\n",
        "# Выводим форму обучающей выборки в виде матрицы Bag of Words\n",
        "print(x_train_01.shape)       \n",
        "# Выводим фрагмент отрезка обучающего текста в виде Bag of Words\n",
        "print(x_train_01[0][0:100])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5842, 15000)\n",
            "[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.\n",
            " 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1.\n",
            " 1. 1. 1. 1.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DfVgSybU4inE"
      },
      "source": [
        "**Шаг 4.** Создание архитектуры нейронной сети.\n",
        "\n",
        "Создайте несложную архитектуру нейронной сети. После этого произведите компиляцию модели с соответствующими параметрами:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4B2O7ZCq4jXf"
      },
      "source": [
        "model_BoW = Sequential()                                            # Создание последовательной модели нейросети\n",
        "model_BoW.add(Dense(184, input_dim=VOCAB_SIZE, activation=\"relu\"))  # Первый полносвязный слой\n",
        "model_BoW.add(Dense(86, activation=\"relu\"))                         # Второй полносвязный слой\n",
        "model_BoW.add(Dense(33, activation=\"relu\"))                         # Третий полносвязный слой\n",
        "model_BoW.add(BatchNormalization())                                 # Слой пакетной нормализации\n",
        "model_BoW.add(Dropout(0.1))                                         # Слой регуляризации Dropout\n",
        "model_BoW.add(Dense(CLASS_COUNT, activation='sigmoid'))             # Выходной полносвязный слой\n",
        "\n",
        "model_BoW.compile(optimizer='adam',                                 # Компиляция модели для обучения на данных вида Bag of Words\n",
        "              loss='categorical_crossentropy', \n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uyLd3_uS58Zv"
      },
      "source": [
        "Обучите модель нейронной сети и посмотрите на результаты точности на проверочной выборке:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmiVZ4Ip572-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6db5a997-f718-4717-92d5-418cf8a1440d"
      },
      "source": [
        "# Обучение сети с помощью функции fit()\n",
        "history = model_BoW.fit(x_train_01,                            # Обучающая выборка Bag of Words\n",
        "                        y_train,                               # Метки классов обучающей выборки\n",
        "                        epochs=20,                             # Количество эпох\n",
        "                        batch_size=32,                         # Размер подвыборки для одного шага по данным на эпохе\n",
        "                        validation_data=(x_test_01, y_test))   # Проверочная выборка и метки классов проверочной выборки"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "183/183 [==============================] - 6s 25ms/step - loss: 0.1396 - accuracy: 0.9801 - val_loss: 0.4498 - val_accuracy: 0.9009\n",
            "Epoch 2/20\n",
            "183/183 [==============================] - 4s 23ms/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 0.3672 - val_accuracy: 0.9205\n",
            "Epoch 3/20\n",
            "183/183 [==============================] - 4s 23ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.3293 - val_accuracy: 0.9233\n",
            "Epoch 4/20\n",
            "183/183 [==============================] - 4s 23ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.2880 - val_accuracy: 0.9306\n",
            "Epoch 5/20\n",
            "183/183 [==============================] - 4s 23ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2657 - val_accuracy: 0.9406\n",
            "Epoch 6/20\n",
            "183/183 [==============================] - 4s 23ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2744 - val_accuracy: 0.9301\n",
            "Epoch 7/20\n",
            "183/183 [==============================] - 4s 23ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2601 - val_accuracy: 0.9274\n",
            "Epoch 8/20\n",
            "183/183 [==============================] - 4s 23ms/step - loss: 7.5948e-04 - accuracy: 1.0000 - val_loss: 0.2358 - val_accuracy: 0.9411\n",
            "Epoch 9/20\n",
            "183/183 [==============================] - 4s 23ms/step - loss: 5.8255e-04 - accuracy: 1.0000 - val_loss: 0.2362 - val_accuracy: 0.9379\n",
            "Epoch 10/20\n",
            "183/183 [==============================] - 4s 23ms/step - loss: 5.1127e-04 - accuracy: 1.0000 - val_loss: 0.2365 - val_accuracy: 0.9361\n",
            "Epoch 11/20\n",
            "183/183 [==============================] - 4s 23ms/step - loss: 4.0804e-04 - accuracy: 1.0000 - val_loss: 0.2278 - val_accuracy: 0.9306\n",
            "Epoch 12/20\n",
            "183/183 [==============================] - 4s 23ms/step - loss: 3.4650e-04 - accuracy: 1.0000 - val_loss: 0.2360 - val_accuracy: 0.9301\n",
            "Epoch 13/20\n",
            "183/183 [==============================] - 4s 23ms/step - loss: 2.9933e-04 - accuracy: 1.0000 - val_loss: 0.2133 - val_accuracy: 0.9347\n",
            "Epoch 14/20\n",
            "183/183 [==============================] - 4s 23ms/step - loss: 2.8193e-04 - accuracy: 1.0000 - val_loss: 0.2072 - val_accuracy: 0.9411\n",
            "Epoch 15/20\n",
            "183/183 [==============================] - 4s 23ms/step - loss: 2.2749e-04 - accuracy: 1.0000 - val_loss: 0.2157 - val_accuracy: 0.9356\n",
            "Epoch 16/20\n",
            "183/183 [==============================] - 4s 23ms/step - loss: 1.9918e-04 - accuracy: 1.0000 - val_loss: 0.1972 - val_accuracy: 0.9434\n",
            "Epoch 17/20\n",
            "183/183 [==============================] - 4s 23ms/step - loss: 1.7379e-04 - accuracy: 1.0000 - val_loss: 0.2117 - val_accuracy: 0.9352\n",
            "Epoch 18/20\n",
            "183/183 [==============================] - 4s 23ms/step - loss: 1.6744e-04 - accuracy: 1.0000 - val_loss: 0.2082 - val_accuracy: 0.9301\n",
            "Epoch 19/20\n",
            "183/183 [==============================] - 4s 23ms/step - loss: 1.4075e-04 - accuracy: 1.0000 - val_loss: 0.2115 - val_accuracy: 0.9311\n",
            "Epoch 20/20\n",
            "183/183 [==============================] - 4s 23ms/step - loss: 1.2978e-04 - accuracy: 1.0000 - val_loss: 0.2160 - val_accuracy: 0.9228\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJD9POc6tYpB"
      },
      "source": [
        "Запишите результаты в таблицу:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHuhzwFVtZIc"
      },
      "source": [
        "# Ваше задание здесь"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_BoW1 = Sequential()                                            # Создание последовательной модели нейросети\n",
        "model_BoW1.add(Dense(256, input_dim=VOCAB_SIZE, activation=\"relu\"))  # Первый полносвязный слой\n",
        "model_BoW1.add(Dense(85, activation=\"relu\"))                         # Второй полносвязный слой\n",
        "model_BoW1.add(Dense(21, activation=\"relu\"))                         # Третий полносвязный слой\n",
        "model_BoW1.add(BatchNormalization())                                 # Слой пакетной нормализации\n",
        "\n",
        "model_BoW1.add(Dense(CLASS_COUNT, activation='sigmoid'))             # Выходной полносвязный слой\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "model_BoW1.compile(optimizer='adam',                                 # Компиляция модели для обучения на данных вида Bag of Words\n",
        "              loss='categorical_crossentropy', \n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "MZ0dpb01K-iK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Обучение сети с помощью функции fit()\n",
        "history = model_BoW1.fit(x_train_01,                            # Обучающая выборка Bag of Words\n",
        "                        y_train,                               # Метки классов обучающей выборки\n",
        "                        epochs=20,                             # Количество эпох\n",
        "                        batch_size=32,                         # Размер подвыборки для одного шага по данным на эпохе\n",
        "                        validation_data=(x_test_01, y_test))   # Проверочная выборка и метки классов проверочной выборки"
      ],
      "metadata": {
        "id": "5DEsErhRK-m4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a01c3fdb-8f1d-4adc-9611-668a6e5a2282"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "183/183 [==============================] - 7s 32ms/step - loss: 0.1250 - accuracy: 0.9841 - val_loss: 0.5065 - val_accuracy: 0.8342\n",
            "Epoch 2/20\n",
            "183/183 [==============================] - 6s 31ms/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 0.3723 - val_accuracy: 0.9187\n",
            "Epoch 3/20\n",
            "183/183 [==============================] - 6s 30ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.3160 - val_accuracy: 0.9466\n",
            "Epoch 4/20\n",
            "183/183 [==============================] - 6s 30ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.2969 - val_accuracy: 0.9470\n",
            "Epoch 5/20\n",
            "183/183 [==============================] - 6s 30ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.2911 - val_accuracy: 0.9388\n",
            "Epoch 6/20\n",
            "183/183 [==============================] - 6s 31ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2705 - val_accuracy: 0.9461\n",
            "Epoch 7/20\n",
            "183/183 [==============================] - 6s 30ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2626 - val_accuracy: 0.9466\n",
            "Epoch 8/20\n",
            "183/183 [==============================] - 6s 31ms/step - loss: 8.3692e-04 - accuracy: 1.0000 - val_loss: 0.2487 - val_accuracy: 0.9452\n",
            "Epoch 9/20\n",
            "183/183 [==============================] - 6s 30ms/step - loss: 7.2337e-04 - accuracy: 1.0000 - val_loss: 0.2435 - val_accuracy: 0.9489\n",
            "Epoch 10/20\n",
            "183/183 [==============================] - 6s 31ms/step - loss: 5.6504e-04 - accuracy: 1.0000 - val_loss: 0.2261 - val_accuracy: 0.9525\n",
            "Epoch 11/20\n",
            "183/183 [==============================] - 6s 31ms/step - loss: 4.6565e-04 - accuracy: 1.0000 - val_loss: 0.2303 - val_accuracy: 0.9484\n",
            "Epoch 12/20\n",
            "183/183 [==============================] - 6s 31ms/step - loss: 3.8842e-04 - accuracy: 1.0000 - val_loss: 0.2361 - val_accuracy: 0.9384\n",
            "Epoch 13/20\n",
            "183/183 [==============================] - 6s 31ms/step - loss: 3.0736e-04 - accuracy: 1.0000 - val_loss: 0.2182 - val_accuracy: 0.9511\n",
            "Epoch 14/20\n",
            "183/183 [==============================] - 6s 31ms/step - loss: 2.4953e-04 - accuracy: 1.0000 - val_loss: 0.2244 - val_accuracy: 0.9438\n",
            "Epoch 15/20\n",
            "183/183 [==============================] - 7s 37ms/step - loss: 2.4806e-04 - accuracy: 1.0000 - val_loss: 0.2262 - val_accuracy: 0.9384\n",
            "Epoch 16/20\n",
            "183/183 [==============================] - 6s 30ms/step - loss: 1.9794e-04 - accuracy: 1.0000 - val_loss: 0.2066 - val_accuracy: 0.9466\n",
            "Epoch 17/20\n",
            "183/183 [==============================] - 6s 31ms/step - loss: 1.5611e-04 - accuracy: 1.0000 - val_loss: 0.2207 - val_accuracy: 0.9370\n",
            "Epoch 18/20\n",
            "183/183 [==============================] - 6s 31ms/step - loss: 1.4981e-04 - accuracy: 1.0000 - val_loss: 0.2075 - val_accuracy: 0.9438\n",
            "Epoch 19/20\n",
            "183/183 [==============================] - 6s 31ms/step - loss: 1.4208e-04 - accuracy: 1.0000 - val_loss: 0.2104 - val_accuracy: 0.9411\n",
            "Epoch 20/20\n",
            "183/183 [==============================] - 6s 31ms/step - loss: 1.1209e-04 - accuracy: 1.0000 - val_loss: 0.1985 - val_accuracy: 0.9452\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "model_BoW1 "
      ],
      "metadata": {
        "id": "Niz6yy1bS8E3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Объем словаря для токенизатора\n",
        "VOCAB_SIZE = 10000\n",
        "\n",
        "# Длина отрезка текста (окна) в словах                        \n",
        "WIN_SIZE   = 1000\n",
        "\n",
        "# Шаг окна разбиения текста на векторы                         \n",
        "WIN_HOP    = 100                          \n",
        "\n",
        "# Токенайзер из Keras для разбиения текста и построения частотного словаря\n",
        "tokenizer = Tokenizer(num_words=VOCAB_SIZE, filters='!\"#$%&()*+,-–—./…:;<=>?@[\\\\]^_`{|}~«»\\t\\n\\xa0\\ufeff', \n",
        "                          lower=True, split=' ', oov_token='неизвестное_слово', char_level=False)"
      ],
      "metadata": {
        "id": "U7JQtBFuK-qQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Получаем словарь частотности \n",
        "tokenizer.fit_on_texts(text_train)"
      ],
      "metadata": {
        "id": "-R-eOtLCK-ti"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Преобразуйте обучающие и проверочные тексты в последовательность индексов согласно частотному словарю Токенайзера:\n"
      ],
      "metadata": {
        "id": "kDGe8OquTiBi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seq_train = tokenizer.texts_to_sequences(text_train)\n",
        "seq_test = tokenizer.texts_to_sequences(text_test)"
      ],
      "metadata": {
        "id": "zTBFrw4ZTiFJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_sequence(sequence,   # Последовательность индексов\n",
        "                   win_size,   # Размер окна для деления на примеры\n",
        "                   hop):       # Шаг окна\n",
        "\n",
        "    # Последовательность разбивается на части до последнего полного окна\n",
        "    return [sequence[i:i + win_size] for i in range(0, len(sequence) - win_size + 1, hop)]"
      ],
      "metadata": {
        "id": "jTtCWE3MTiIt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def vectorize_sequence(seq_list,    # Список последовательностей индексов \n",
        "                       win_size,    # Размер окна для деления на примеры\n",
        "                       hop):        # Шаг окна\n",
        "\n",
        "    # В списке последовательности следуют в порядке их классов (их кол-во сповпадает с кол-вом классов)\n",
        "    class_count = len(seq_list)\n",
        "\n",
        "    # Списки для исходных векторов и категориальных меток класса\n",
        "    x, y = [], []\n",
        "\n",
        "    # Для каждого класса:\n",
        "    for cls in range(class_count):\n",
        "\n",
        "        # Разбиение последовательности класса cls на отрезки\n",
        "        vectors = split_sequence(seq_list[cls], win_size, hop)\n",
        "\n",
        "        # Добавление отрезков в выборку\n",
        "\n",
        "        x += vectors\n",
        "        \n",
        "        # Для всех отрезков класса cls добавление меток класса в виде OHE\n",
        "        y += [utils.to_categorical(cls, class_count)] * len(vectors)\n",
        "\n",
        "    # Возврат результатов как numpy-массивов\n",
        "    return np.array(x), np.array(y)"
      ],
      "metadata": {
        "id": "KDxaI4wXWxbB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Формирование обучающей выборки\n",
        "x_train, y_train = vectorize_sequence(seq_train, WIN_SIZE, WIN_HOP) \n",
        "# Формирование тестовой выборки\n",
        "x_test, y_test = vectorize_sequence(seq_test, WIN_SIZE, WIN_HOP)\n",
        "\n",
        "# Проверка формы сформированных данных\n",
        "print(x_train.shape, y_train.shape)\n",
        "print(x_test.shape, y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j6O3-Wi8Wxf-",
        "outputId": "249f0253-04b9-4a96-8d54-46584c00c510"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(17640, 1000) (17640, 6)\n",
            "(6686, 1000) (6686, 6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# На входе .sequences_to_matrix() ожидает список, .tolist() выполняет преобразование к типу данных 'список'\n",
        "x_train_01 = tokenizer.sequences_to_matrix(x_train.tolist())\n",
        "x_test_01 = tokenizer.sequences_to_matrix(x_test.tolist())\n",
        "\n",
        "# Выводим форму обучающей выборки в виде матрицы Bag of Words\n",
        "print(x_train_01.shape)       \n",
        "# Выводим фрагмент отрезка обучающего текста в виде Bag of Words\n",
        "print(x_train_01[0][0:100])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_e4AK0DfWxj0",
        "outputId": "8360451d-2ce1-460d-f92b-d4fd74610523"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(17640, 10000)\n",
            "[0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1.\n",
            " 0. 0. 1. 1. 0. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0.\n",
            " 0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 1. 0. 0. 0. 0.\n",
            " 1. 1. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1.\n",
            " 0. 0. 1. 1.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_BoW = Sequential()                                            # Создание последовательной модели нейросети\n",
        "model_BoW.add(Dense(184, input_dim=VOCAB_SIZE, activation=\"relu\"))  # Первый полносвязный слой\n",
        "model_BoW.add(Dense(86, activation=\"relu\"))                         # Второй полносвязный слой\n",
        "model_BoW.add(Dense(33, activation=\"relu\"))                         # Третий полносвязный слой\n",
        "model_BoW.add(BatchNormalization())                                 # Слой пакетной нормализации\n",
        "model_BoW.add(Dropout(0.1))                                         # Слой регуляризации Dropout\n",
        "model_BoW.add(Dense(CLASS_COUNT, activation='sigmoid'))             # Выходной полносвязный слой\n",
        "\n",
        "model_BoW.compile(optimizer='adam',                                 # Компиляция модели для обучения на данных вида Bag of Words\n",
        "              loss='categorical_crossentropy', \n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "qSX5u1LaUNI7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Обучение сети с помощью функции fit()\n",
        "history = model_BoW.fit(x_train_01,                            # Обучающая выборка Bag of Words\n",
        "                        y_train,                               # Метки классов обучающей выборки\n",
        "                        epochs=20,                             # Количество эпох\n",
        "                        batch_size=32,                         # Размер подвыборки для одного шага по данным на эпохе\n",
        "                        validation_data=(x_test_01, y_test))   # Проверочная выборка и метки классов проверочной выборки"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-b_bMxVUNL_",
        "outputId": "d3b9104c-f0da-46a9-bf41-db3c0fa52896"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "552/552 [==============================] - 11s 18ms/step - loss: 0.0600 - accuracy: 0.9871 - val_loss: 0.4312 - val_accuracy: 0.8525\n",
            "Epoch 2/20\n",
            "552/552 [==============================] - 9s 17ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.4092 - val_accuracy: 0.8576\n",
            "Epoch 3/20\n",
            "552/552 [==============================] - 11s 19ms/step - loss: 8.4706e-04 - accuracy: 1.0000 - val_loss: 0.3871 - val_accuracy: 0.8630\n",
            "Epoch 4/20\n",
            "552/552 [==============================] - 9s 17ms/step - loss: 4.1004e-04 - accuracy: 1.0000 - val_loss: 0.3897 - val_accuracy: 0.8570\n",
            "Epoch 5/20\n",
            "552/552 [==============================] - 9s 17ms/step - loss: 2.7310e-04 - accuracy: 1.0000 - val_loss: 0.4063 - val_accuracy: 0.8527\n",
            "Epoch 6/20\n",
            "552/552 [==============================] - 9s 17ms/step - loss: 1.5924e-04 - accuracy: 1.0000 - val_loss: 0.3776 - val_accuracy: 0.8648\n",
            "Epoch 7/20\n",
            "552/552 [==============================] - 9s 17ms/step - loss: 1.1405e-04 - accuracy: 1.0000 - val_loss: 0.3827 - val_accuracy: 0.8636\n",
            "Epoch 8/20\n",
            "552/552 [==============================] - 9s 17ms/step - loss: 8.1610e-05 - accuracy: 1.0000 - val_loss: 0.3836 - val_accuracy: 0.8625\n",
            "Epoch 9/20\n",
            "552/552 [==============================] - 9s 17ms/step - loss: 5.6679e-05 - accuracy: 1.0000 - val_loss: 0.3669 - val_accuracy: 0.8693\n",
            "Epoch 10/20\n",
            "552/552 [==============================] - 9s 17ms/step - loss: 4.4030e-05 - accuracy: 1.0000 - val_loss: 0.4032 - val_accuracy: 0.8558\n",
            "Epoch 11/20\n",
            "552/552 [==============================] - 9s 17ms/step - loss: 0.0135 - accuracy: 0.9963 - val_loss: 0.5328 - val_accuracy: 0.8290\n",
            "Epoch 12/20\n",
            "552/552 [==============================] - 9s 17ms/step - loss: 3.2593e-04 - accuracy: 1.0000 - val_loss: 0.5490 - val_accuracy: 0.8241\n",
            "Epoch 13/20\n",
            "552/552 [==============================] - 9s 17ms/step - loss: 1.8864e-04 - accuracy: 1.0000 - val_loss: 0.5367 - val_accuracy: 0.8356\n",
            "Epoch 14/20\n",
            "552/552 [==============================] - 9s 17ms/step - loss: 9.7308e-05 - accuracy: 1.0000 - val_loss: 0.5875 - val_accuracy: 0.8320\n",
            "Epoch 15/20\n",
            "552/552 [==============================] - 9s 17ms/step - loss: 7.6187e-05 - accuracy: 1.0000 - val_loss: 0.6476 - val_accuracy: 0.8214\n",
            "Epoch 16/20\n",
            "552/552 [==============================] - 9s 16ms/step - loss: 5.4281e-05 - accuracy: 1.0000 - val_loss: 0.5840 - val_accuracy: 0.8346\n",
            "Epoch 17/20\n",
            "552/552 [==============================] - 9s 17ms/step - loss: 3.3969e-05 - accuracy: 1.0000 - val_loss: 0.5895 - val_accuracy: 0.8338\n",
            "Epoch 18/20\n",
            "552/552 [==============================] - 9s 17ms/step - loss: 2.5391e-05 - accuracy: 1.0000 - val_loss: 0.6022 - val_accuracy: 0.8326\n",
            "Epoch 19/20\n",
            "552/552 [==============================] - 9s 17ms/step - loss: 1.4296e-05 - accuracy: 1.0000 - val_loss: 0.5835 - val_accuracy: 0.8391\n",
            "Epoch 20/20\n",
            "552/552 [==============================] - 9s 17ms/step - loss: 4.1738e-05 - accuracy: 1.0000 - val_loss: 0.6719 - val_accuracy: 0.8142\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Для формирования таблицы\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "ndG1XPAeUNPq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame({'VOCAB_SIZE':[15000, 15000, 10000], 'WIN_SIZE':[3000, 3000, 1000], 'WIN_HOP':[300, 300, 100], 'Dropout':[0.1, 0, 0.1],\n",
        "                   'Dense':[(184,86,33), (256,85,21), (184,86,33)], 'val_accuracy':[0.92, 0.95, 0.81]})"
      ],
      "metadata": {
        "id": "d1CAIYqOYUS1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6FQ_fQ6nYUWa",
        "outputId": "9d537853-78d4-472a-97ce-c56440d35e8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   VOCAB_SIZE  WIN_SIZE  WIN_HOP  Dropout          Dense  val_accuracy\n",
            "0       15000      3000      300      0.1  (184, 86, 33)          0.92\n",
            "1       15000      3000      300      0.0  (256, 85, 21)          0.95\n",
            "2       10000      1000      100      0.1  (184, 86, 33)          0.81\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ll7CiWZ_YUaa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}